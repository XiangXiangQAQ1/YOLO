# YOLOV5 modelæ€»ç±»

## Conv
- conv: è€æœ‹å‹ï¼Œå·ç§¯å±‚äº†ï¼Œä¸æ˜¯äººå®¶å†™çš„æ˜¯çœŸé«˜çº§å•Šï¼Œå¥½å¥½å­¦å­¦,å­¦ä¹ çš„æ˜¯å„ç§å·ç§¯æ ¸ã€‚è¾“å…¥æ˜¯å›¾åƒï¼Œä¸€èˆ¬ä¸ºå½©è‰²å›¾åƒï¼Œæœ‰ä¸‰ä¸ªé€šé“ã€‚æ¨¡å‹å°±ä¼šè‡ªåŠ¨åˆ›å»º 64 ä¸ªã€Œ3Ã—3Ã—3 çš„å·ç§¯æ ¸ã€æ¥å‚ä¸å­¦ä¹ ï¼Œæ¯ä¸ªå·ç§¯æ ¸éƒ½èƒ½å­¦ä¼šæå–ä¸åŒçš„å›¾åƒç‰¹å¾ï¼
- ä½†æ˜¯å’±ä»¬ä½¿ç”¨çš„æ˜¯ç‰¹å¾å›¾ï¼Œåƒ`x = torch.relu(self.bn1(self.conv1(x))) # [B,24,32,32]`ä½¿ç”¨çš„å°±æ˜¯ç‰¹å¾å›¾ï¼Œæœ€ç»ˆå¯ä»¥æŠŠæ‰€æœ‰ç‰¹å¾å›¾å¹³å±• æˆä¸€ç»´ï¼Œç”¨äºçº¿æ€§å±‚è¿æ¥ã€‚
- å°±æ˜¯æˆ‘ä»¬å‰å‘ä¼ æ’­çš„æ—¶å€™ç”¨çš„æ˜¯ç‰¹å¾å›¾ï¼Œåå‘ä¼ æ’­æ›´æ–°çš„æ˜¯å·ç§¯æ ¸
```python
conv = nn.Conv2d(3, 64, kernel_size=3)
```

- self.bn = nn.BatchNorm2d(c2),å½’ä¸€åŒ–ï¼Œå‡è½»æ¢¯åº¦æ¶ˆå¤±å’Œæ¢¯åº¦çˆ†ç‚¸
- è¿™if else ç›´æ¥ç»™æˆ‘æ•´ä¸ä¼šäº†ã€‚
```pyhton
self.act = self.default_act if act is True else act if isinstance(act, nn.Module) else nn.Identity()
```

- Convæ˜¯ä¸€ä¸ªå…¨è¿æ¥å±‚ï¼Œæ¯ä¸ªè¾“å…¥å±‚å’Œè¾“å‡ºå±‚éƒ½éœ€è¦å­¦ä¹ ä¸€ä¸ªå·ç§¯æ ¸ï¼Œå‚æ•°çš„æ€»æ•°ä¸º$c_{in} *c_{out}*k_h*k_w$, $k_h$å’Œ$k_w$ä¸ºé«˜å’Œå®½

### DWConv Depthwise Convolutionï¼ˆé€é€šé“å·ç§¯ï¼‰
- ä½¿ç”¨çˆ¶ç±»çš„init å‡½æ•°ï¼Œç»§æ‰¿çˆ¶ç±»
- æ·±åº¦åˆ†ç¦»å·ç§¯(åˆ†ç»„å·ç§¯),æˆ‘ä»¬å°†å·ç§¯å±‚åˆ†ä¸ºä¸åŒçš„ç»„ï¼Œè€Œæ¯ä¸ªç»„è¿›è¡Œç‹¬ç«‹çš„å·ç§¯ï¼Œè¿™æ ·ç»„é—´å°±æ²¡æœ‰ç›¸äº’è¿æ¥ï¼Œå¯ä»¥æœ‰æ•ˆæé«˜è®¡ç®—æ•ˆç‡ï¼Œå‡è½»è®¡ç®—é‡ã€‚nn.Conv2dä¸­gå³ä¸ºåˆ†ç»„æ•°ã€‚
    - ä¸”åˆ†ç»„æ˜¯ä¸¥æ ¼æŒ‰ç…§é¡ºåºè¿›è¡Œçš„ã€‚


```python
self.conv = nn.Conv2d(c1, c2, k, s, autopad(k, p, d), groups=g, dilation=d, bias=False) 
```
```python

class DWConv(Conv):
    # Depth-wise convolution
    def __init__(self, c1, c2, k=1, s=1, d=1, act=True):  # ch_in, ch_out, kernel, stride, dilation, activation
        super().__init__(c1, c2, k, s, g=math.gcd(c1, c2), d=d, act=act)
```


### Tranform(FFN)
- â€œå‘å‰å‘åæŸ¥æ‰¾â€çš„æ˜¯ Attention éƒ¨åˆ†ï¼Œå®ƒé€šè¿‡å¯¹ Q/K/V åšåŠ æƒå¹³å‡ï¼Œè®©æ¯ä¸ªè¾“å‡ºä½ç½®éƒ½èƒ½å¤Ÿè®¿é—®åºåˆ—çš„æ‰€æœ‰ä½ç½®ã€‚
- FFN ä»…ä»…èµ·åˆ°â€œå¯¹å·²ç»èåˆä¸Šä¸‹æ–‡çš„è¡¨ç¤ºâ€åšé€ä½ç½®éçº¿æ€§å˜æ¢çš„ä½œç”¨ï¼Œå®ƒä¸è´Ÿè´£â€œæŸ¥æ‰¾â€æˆ–â€œèšåˆâ€ä¸åŒä½ç½®çš„ä¿¡æ¯ã€‚
- æ¢å¥è¯è¯´ï¼Œåœ¨ Transformer é‡Œï¼Œæ¯ä¸€å±‚éƒ½ä¼šå…ˆåšä¸€æ¬¡ Attentionï¼ˆè·å–ä¸Šä¸‹æ–‡ï¼‰ï¼Œç„¶åç´§è·Ÿä¸€ä¸ª FFNï¼ˆå•ä½ç½®éçº¿æ€§ï¼‰ã€‚åªæœ‰æŠŠä¸¤è€…ä¸²åœ¨ä¸€èµ·ï¼Œæ‰æ—¢ä¿è¯äº†â€œåºåˆ—å†…éƒ¨ä»»æ„ä½ç½®çš„äº¤äº’â€ï¼Œåˆè¡¥å……äº†è¶³å¤Ÿçš„éçº¿æ€§è¡¨è¾¾èƒ½åŠ›ã€‚


### Bottleneck(ç“¶é¢ˆ)
- å…ˆå‹ç¼©å†æ‰©å¼ ï¼Œå‡å°‘è®¡ç®—é‡
    - ä½¿ç”¨è¿‡æ¸¡å·ç§¯å±‚å¯ä»¥å‡å°‘å‚æ•°æ•°é‡ï¼Œæœ¬æ¥å­¦ä¹ (3*3*c1*c2)çš„å·ç§¯æ ¸,ç°åœ¨å­¦ä¹ (c1*c2/2 + 3*3*c2/2*c2), è‹¥$c1=c2$ï¼Œåˆ™å¤§çº¦å‡å°‘äº†ä¸€åŠçš„è®¡ç®—æˆæœ¬
- æ®‹å·®è¿æ¥å¯ä»¥è§£å†³æ¢¯åº¦æ¶ˆå¤±çš„é—®é¢˜ï¼Œå› ä¸ºåœ¨åå‘è¿‡ç¨‹ä¸­è‡³å°‘æœ‰ä¸€ä¸ªæ¢¯åº¦1ã€‚ä½¿å¾—æ·±å±‚ç½‘ç»œçš„æ¢¯åº¦æ¶ˆå¤±é—®é¢˜å¾—åˆ°ç¼“è§£ï¼Œå¹¶åŠ é€Ÿæ”¶æ•›ã€‚
- å½“ç„¶ï¼Œè¿™åªèƒ½è§£å†³ä¸€å±‚çš„æ¢¯åº¦æ¶ˆå¤±ï¼Œæ‰€ä»¥ä½¿ç”¨nå±‚çš„è¯ï¼Œå°±å½¢æˆäº†å…¨å±€æ›´ç¨³å®šçš„æ¢¯åº¦é€šé“ï¼Œæ¯”è¾ƒå¥½çš„è§£å†³äº†æ¢¯åº¦æ¶ˆå¤±çš„é—®é¢˜ã€‚
```python
   def forward(self, x):
        return x + self.cv2(self.cv1(x)) if self.add else self.cv2(self.cv1(x))
``` 
```python
class Bottleneck(nn.Module):
    # Standard bottleneck
    def __init__(self, c1, c2, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, shortcut, groups, expansion
        super().__init__()
        c_ = int(c2 * e)  # hidden channels
        self.cv1 = Conv(c1, c_, 1, 1) # kernel =1
        self.cv2 = Conv(c_, c2, 3, 1, g=g) # kernel =3
        self.add = shortcut and c1 == c2

```
- ä»€ä¹ˆæ˜¯åå‘ä¼ æ’­ï¼šå°±æ˜¯ç”¨é“¾å¼æ³•åˆ™ï¼ŒæŠŠå¯¹xçš„æ±‚å¯¼ä»æœ€åä¸€å±‚ä¼ åˆ°å‰é¢æ¥ï¼Œä¸”ç”¨æœ€é€Ÿä¸‹é™æ³•é€”ä¸­çš„å„ä¸ªå±‚çš„æƒé‡

#### BottleneckCSP(Cross Stage Partial Network)
- å®ƒæ˜¯ä¸€ä¸ªå·ç§¯ç¥ç»ç½‘ç»œé‡Œçš„æ¨¡å—ï¼Œç”¨äºå¤„ç†å›¾ç‰‡çš„ç‰¹å¾å›¾ï¼ˆfeature mapï¼‰ï¼Œè®©ç‰¹å¾å›¾å˜å¾—æ›´æ·±ã€æ›´ä¸°å¯Œï¼Œä½†è®¡ç®—é‡æ›´å°ã€æ›´ç¨³å®šã€‚
- é¦–å…ˆï¼Œcv1å’Œcv2éƒ½æ˜¯å­¦ä¹ å¤§å°ä¸º1çš„æ ¸ï¼›ä¸”é€šé“æ•°ç›¸å¯¹äºè¾“å‡ºå‡åŠã€‚
- ä¹‹åå·¦è¾¹ä¸»å¹²è·¯å­¦ä¹ nå±‚çš„Bottlneckå±‚ï¼Œå­¦ä¹ å¤æ‚çš„ç‰¹å¾å‘` self.m = nn.Sequential(*(Bottleneck(c_, c_, shortcut, g, e=1.0) for _ in range(n)))`
- å³è¾¹shortcutè·¯ä¸ºæ’ç­‰å˜æ¢ï¼Œä¿ç•™äº†å›¾ç‰‡çš„æµ…å±‚ç‰¹å¾ã€‚
- æœ€åå†ç”¨`cat`ï¼Œå°†ä¸¤å±‚æ‹¼æ¥èµ·æ¥ï¼Œ(æ ¹æ®é€šé“æ•°æ‹¼æ¥)
```bash
          x
         / \
        |   |
      cv1   cv2
       |     |
      m()   identity
       |     |
      cv3   |
        \   /
        cat(y1, y2)
           |
          BN
           |
          SiLU
           |
          cv4
           â†“
         Output
```
```python
class BottleneckCSP(nn.Module):
    # CSP Bottleneck https://github.com/WongKinYiu/CrossStagePartialNetworks
    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion
        super().__init__()
        c_ = int(c2 * e)  # hidden channels
        self.cv1 = Conv(c1, c_, 1, 1)
        self.cv2 = nn.Conv2d(c1, c_, 1, 1, bias=False)
        self.cv3 = nn.Conv2d(c_, c_, 1, 1, bias=False)
        self.cv4 = Conv(2 * c_, c2, 1, 1)
        self.bn = nn.BatchNorm2d(2 * c_)  # applied to cat(cv2, cv3)
        self.act = nn.SiLU()
        self.m = nn.Sequential(*(Bottleneck(c_, c_, shortcut, g, e=1.0) for _ in range(n)))

    def forward(self, x):
        y1 = self.cv3(self.m(self.cv1(x)))
        y2 = self.cv2(x)
        return self.cv4(self.act(self.bn(torch.cat((y1, y2), 1)))) # è¡¨ç¤ºåœ¨é€šé“æ•°æ‹¼æ¥ã€‚
```


### cross convolution(äº¤å‰å·ç§¯ä¸‹é‡‡æ ·)
- ç°åœ¨æˆ‘ä»¬çš„å·ç§¯æ ¸ä¸º1ç»´çš„ï¼Œä¸”ä¸€ä¸ªè¾“å…¥å±‚å¯¹åº”ä¸€ä¸ªè¾“å‡ºå±‚ã€‚ç§°ä¸º(Depthwise)ã€‚
```md
å‡è®¾ä½ æœ‰ä¸€ä¸ªè¾“å…¥å¼ é‡ï¼š[C_in=3, H=32, W=32];
ä½ ç”¨ä¸€ä¸ª 3Ã—3 çš„ depthwise å·ç§¯ï¼š
- ä½ æœ‰ 3 ä¸ªå·ç§¯æ ¸ï¼ˆæ¯é€šé“ä¸€ä¸ªï¼‰ï¼›
- æ¯ä¸ªå·ç§¯æ ¸æ˜¯ 3Ã—3ï¼Œåªä½œç”¨äº è‡ªå·±çš„é€šé“ï¼›
- è¾“å‡ºä»ç„¶æ˜¯ 3 ä¸ªé€šé“ï¼Œä¸ä¼šæ··åˆé€šé“ä¹‹é—´çš„ä¿¡æ¯ã€‚
```
- cross convolution é€šè¿‡ä¸¤ä¸ªæ–¹å‘çš„äº¤å‰å·ç§¯æ¥æå–ç‰¹å¾(1,k),(k,1)


## C3( CSP Bottleneck with 3 Convolutions)
- C3 æ˜¯ YOLOv5 çš„ä¼˜åŒ–ç‰ˆ CSP æ¨¡å—ï¼Œæ›´é«˜æ•ˆ;BottleneckCSP æ˜¯åŸå§‹å®šä¹‰çš„ CSPï¼Œæ›´ä¸¥è°¨
- ä¸”C3çš„convæ˜¯å†ultralyics å®šä¹‰çš„ï¼Œè€Œä¸æ˜¯åŸå§‹çš„`nn.Conv2d`
```bash
          x
         / \
        |   |
      cv1   cv2
       |     |
      m()  identity
       |     |
        \   /
        cat(y1, y2)
             |
            cv3
             â†“
          Output

```

```python
class C3(nn.Module):
    # CSP Bottleneck with 3 convolutions
    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion
        super().__init__()
        c_ = int(c2 * e)  # hidden channels
        self.cv1 = Conv(c1, c_, 1, 1)
        self.cv2 = Conv(c1, c_, 1, 1)
        self.cv3 = Conv(2 * c_, c2, 1)  # optional act=FReLU(c2)
        self.m = nn.Sequential(*(Bottleneck(c_, c_, shortcut, g, e=1.0) for _ in range(n)))

    def forward(self, x):
        return self.cv3(torch.cat((self.m(self.cv1(x)), self.cv2(x)), 1))

```

1. **c3x**
å°†bottlenckæ›¿æ¢æˆCrossConv
```python
self.m = nn.Sequential(*(CrossConv(c_, c_, 3, 1, g, 1.0, shortcut) for _ in range(n)))
```

2. **C3TR**
- æŠŠ Bottleneck æ›¿æ¢æˆäº†Transformer Blockã€‚

3. **C3SPP**
- æ›¿æ¢ä¸º SPP æ¨¡å—ï¼ˆç©ºé—´é‡‘å­—å¡”æ± åŒ–ï¼‰ï¼Œç”¨ä¸åŒå°ºå¯¸çš„ max pooling æ¥å¤„ç†å›¾åƒ

4. **C3Ghost**
- ä½¿ç”¨ GhostNet çš„æ€æƒ³ï¼šæŠŠä¸€éƒ¨åˆ†ç‰¹å¾ç”¨ cheap æ“ä½œï¼ˆå¦‚ depthwise convï¼‰æ¥ç”Ÿæˆã€‚
```python 
self.m = nn.Sequential(*(GhostBottleneck(...) for _ in range(n)))
s
```


## SPP(Spatial Pyramid Pooling)
- ä½¿ç”¨ä¸‰ä¸ªä¸åŒçš„maxpoolå±‚æå–ä¿¡æ¯ï¼Œæœ€åæ•´åˆä¸‰ä¸ªæ± åŒ–å±‚ï¼Œå†é€šè¿‡`cv2`å·ç§¯ã€‚
- Pyramidï¼ˆé‡‘å­—å¡”ï¼‰ï¼šæŒ‡çš„æ˜¯å®ƒä½¿ç”¨äº†å¤šç§ä¸åŒå°ºåº¦çš„æ± åŒ–æ ¸ï¼Œæ¯”å¦‚ 5Ã—5ã€9Ã—9ã€13Ã—13ï¼Œè¿™äº›å¤§å°å°±åƒä¸€ä¸ªé‡‘å­—å¡”çš„ä¸åŒâ€œå±‚çº§â€ï¼Œæ„Ÿå—é‡ä»å°åˆ°å¤§
```md
               x
               |
             Conv1x1 (é™é€šé“)
               |
         â”Œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”
         â”‚     â”‚      â”‚      â”‚      â”‚
        ID   Max5   Max9   Max13  ï¼ˆåˆ†åˆ«å¯¹åº” kernel_sizeï¼‰
         â”‚     â”‚      â”‚      â”‚
         â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”˜
               â”‚
            Concat
               â”‚
             Conv1x1 (å‡é€šé“)
               â†“
            è¾“å‡ºç‰¹å¾å›¾

```

```python
class SPP(nn.Module):
    # Spatial Pyramid Pooling (SPP) layer https://arxiv.org/abs/1406.4729
    def __init__(self, c1, c2, k=(5, 9, 13)):
        super().__init__()
        c_ = c1 // 2  # hidden channels
        self.cv1 = Conv(c1, c_, 1, 1)
        self.cv2 = Conv(c_ * (len(k) + 1), c2, 1, 1)
        self.m = nn.ModuleList([nn.MaxPool2d(kernel_size=x, stride=1, padding=x // 2) for x in k])

    def forward(self, x):
        x = self.cv1(x)
        with warnings.catch_warnings():
            warnings.simplefilter('ignore')  # suppress torch 1.9.0 max_pool2d() warning
            return self.cv2(torch.cat([x] + [m(x) for m in self.m], 1))
```

- ä¼˜ç‚¹ï¼šé€šè¿‡ä¸åŒå¤§å°çš„æ± åŒ–æ ¸æå–å±€éƒ¨å’Œå…¨å±€ä¿¡æ¯ï¼›ä¸”æœ‰åŠ©äºæ£€æµ‹ä¸åŒå¤§å°çš„ç›®æ ‡ï¼ŒMaxPool æ˜¯æ— å‚æ•°æ“ä½œï¼Œä¸å¢åŠ æ¨¡å‹å®¹é‡

### Maxpool
- maxpoolé€šè¿‡æå–æŒ‡å®šåŒºåŸŸçš„æœ€å¤§å€¼æ¥æå–ç‰¹å¾ï¼Œkernel_size=5ï¼Œè¡¨ç¤ºæ¯æ¬¡ç”¨5*5çš„æ¡†æå–å…¶ä¸­çš„æœ€å¤§å€¼ã€‚
- paddingç”¨äºè¡¥é›¶ï¼Œä¿æŒå›¾ç‰‡å°ºå¯¸ä¸å˜ã€‚
```python
nn.MaxPool2d(kernel_size=5, stride=1, padding=2)
```


### SPPF(Spatial Pyramid Pooling - Fast )
- ç”¨æ›´å°‘çš„è®¡ç®—è·å¾—ç±»ä¼¼çš„å¤šå°ºåº¦æ„Ÿå—é‡æ•ˆæœ.ä½¿ç”¨5*5çš„maxpoolçš„åµŒå¥—ã€‚è·å¾—äº†å’ŒSPPä¸€æ ·5*5,9*9,13*13åŒæ ·çš„ç»“æœ
    - å› ä¸ºæˆ‘ä»¬ä½¿ç”¨çš„stride=1ï¼Œæ¯æ¬¡ç§»åŠ¨1ï¼Œç›¸å½“äºæ‰©å¤§ä¸€å±‚ï¼Œè€Œ5*5ï¼Œå»é™¤æœ¬èº«çš„ä¸€å±‚ï¼Œåˆšå¥½è¦æ‰©å¤§å››å±‚

```python
self.m = nn.MaxPool2d(kernel_size=k, stride=1, padding=k // 2)

 y1 = self.m(x)
            y2 = self.m(y1)
            return self.cv2(torch.cat((x, y1, y2, self.m(y2)), 1))
```



## Focus
- æŠŠç©ºé—´ä¿¡æ¯ï¼ˆå®½ã€é«˜ï¼‰å‹ç¼©åˆ°é€šé“ç»´åº¦ä¸­ï¼Œä»è€Œå‡å°ç©ºé—´å°ºå¯¸çš„åŒæ—¶ä¿ç•™æ›´å¤šç»†èŠ‚,å¹¶ä¸”ä¿ç•™äº†ä¿¡æ¯ï¼Œä¸åƒæ± åŒ–ä¸€æ ·ä¼šä¸¢å¤±ä¿¡æ¯ã€‚
```python
x[..., ::2, ::2] â†’ ä»å¶æ•°è¡Œå¶æ•°åˆ—å–åƒç´ 
x[..., 1::2, ::2] â†’ å¥‡æ•°è¡Œå¶æ•°åˆ—
x[..., ::2, 1::2] â†’ å¶æ•°è¡Œå¥‡æ•°åˆ—
x[..., 1::2, 1::2] â†’ å¥‡æ•°è¡Œå¥‡æ•°åˆ—
```
è¿™æ ·å°±ä»åŸå›¾åƒä¸­æå–äº† 4 ä¸ªå­å›¾ï¼Œæ¯ä¸ªå¤§å°æ˜¯ [B, C, H/2, W/2]
- å‡è®¾è¾“å…¥å›¾åƒæ˜¯ 640x640 çš„ RGB å›¾ç‰‡ [1, 3, 640, 640]ï¼Œç»è¿‡ Focus åï¼šè¾“å‡ºç»´åº¦æ˜¯ [1, 12, 320, 320]ï¼ˆC=3ï¼Œå‹ç¼©ç©ºé—´ç»´åº¦åˆ°é€šé“ä¸Šï¼Œ4C=12ï¼‰
    - ç©ºé—´å°ºå¯¸å‡åŠï¼Œä½†å†…å®¹æ²¡ä¸¢å¤±ï¼ˆåªæ˜¯é‡æ–°æ’åˆ—äº†ï¼‰ï¼Œä¾¿äºåç»­æ“ä½œã€‚

- Focus æ˜¯ YOLOv5 è¾“å…¥é˜¶æ®µçš„ç¬¬ä¸€æ­¥ã€‚å®ƒé€šå¸¸åæ¥ä¸€ä¸ªæ™®é€šçš„å·ç§¯å±‚åšç‰¹å¾æå–ã€‚ä¾‹å¦‚

## Ghost
### GhostConv
- å·ç§¯å­¦ä¹ çš„ä»£ä»·å¾ˆæ˜‚è´µï¼Œæ‰€ä»¥æˆ‘ä»¬å…ˆä¸»è¦å­¦ä¹ ä¸€éƒ¨åˆ†ç‰¹å¾ï¼Œå¦ä¸€éƒ¨åˆ†å°±å…ˆå½“å¹½çµã€‚`gruop =c_`

```python
class GhostConv(nn.Module):
    def __init__(self, c1, c2, k=1, s=1, g=1, act=True):  # ch_in, ch_out, kernel, stride, groups
        super().__init__()
        c_ = c2 // 2  # hidden channels
        self.cv1 = Conv(c1, c_, k, s, None, g, act=act)
        self.cv2 = Conv(c_, c_, 5, 1, None, c_, act=act)// group =c_

    def forward(self, x):
        y = self.cv1(x)
        return torch.cat((y, self.cv2(y)), 1)
```

### Ghost Bottleneck
- ä½¿ç”¨Ghost convçš„ Bottenlenck;ä¾ç„¶æ˜¯å…ˆå‹ç¼©å†å‡ç»´ï¼›ä½†æœ‰ä¸¤ç‚¹åŒºåˆ«ï¼Œå®ƒå¯¹äºs==2å•ç‹¬å¤„ç†äº†ã€‚GhostNet çš„è®¾è®¡å“²å­¦ä¸€è‡´ï¼šä¸»åˆ†æ”¯ç”Ÿæˆä¸»ç‰¹å¾ï¼ŒGhost åˆ†æ”¯ç”Ÿæˆ cheap ç‰¹å¾ï¼Œä¸‹é‡‡æ ·ç”¨æ­£ç»Ÿè½»é‡å·ç§¯å¤„ç†ã€‚
- Ghost convçš„ä¸»è¦ä»»åŠ¡ä¸ºæå–ç‰¹å¾ï¼Œè€Œä¸æ˜¯å¤„ç†ç©ºé—´ç»“æ„ï¼Œå¯¹å®ƒè¿›è¡Œä¸‹é‡‡æ ·ï¼Œä¼šè®©æœ¬æ¥ç®€å•çš„ç»“æ„å˜å¾—å¤æ‚ï¼›
- è€Œä¸”ä½¿ç”¨DWconvè¿›è¡Œä¸‹é‡‡æ ·ä¹Ÿéå¸¸è½»é‡ã€‚é«˜æ•ˆ
```bash
+--------------------+
|      Input         |
+--------------------+
          |
          v
+--------------------+
|   GhostConv (1x1)  |
+--------------------+
          |
          v
+----------------------------+
|  DWConv (if stride == 2)  |
|     or Identity           |
+----------------------------+
          |
          v
+----------------------------+
|   GhostConv (1x1, linear) |
+----------------------------+
          |
          v
+-----------------------------+
|      Shortcut path:        |
|  DWConv + Conv (if s=2)    |
|      or Identity           |
+-----------------------------+
          |
          v
+----------------------+
|   Add + Output       |
+----------------------+
```

```python
class GhostBottleneck(nn.Module):
    # Ghost Bottleneck https://github.com/huawei-noah/ghostnet
    def __init__(self, c1, c2, k=3, s=1):  # ch_in, ch_out, kernel, stride
        super().__init__()
        c_ = c2 // 2
        self.conv = nn.Sequential(
            GhostConv(c1, c_, 1, 1),  # pw
            DWConv(c_, c_, k, s, act=False) if s == 2 else nn.Identity(),  # dw
            GhostConv(c_, c2, 1, 1, act=False))  # pw-linear
        self.shortcut = nn.Sequential(DWConv(c1, c1, k, s, act=False), Conv(c1, c2, 1, 1,
                                                                            act=False)) if s == 2 else nn.Identity()

    def forward(self, x):
        return self.conv(x) + self.shortcut(x)
```

## Expand and Contract

### Contract
- Contract width-height into channels, i.e. x(1,64,80,80) to x(1,256,40,40)


### expand
- Expand channels into width-height, i.e. x(1,64,80,80) to x(1,16,160,160)



## DetectMultiBackend
åœ¨æ¨ç†è¿‡ç¨‹ä¸­ï¼ŒDetectMultiBackend ä¼šè°ƒç”¨ä¸åŒæ¨ç†åç«¯çš„å®ç°ã€‚ä¾‹å¦‚ï¼Œä½¿ç”¨ PyTorch åç«¯æ—¶ï¼Œå®ƒä¼šè°ƒç”¨ model(im) æ‰§è¡Œå‰å‘æ¨ç†ï¼›è€Œåœ¨ä½¿ç”¨ ONNX æˆ– TensorRT æ—¶ï¼Œå®ƒä¼šè°ƒç”¨å¯¹åº”çš„æ¨ç†å¼•æ“è¿›è¡Œæ¨ç†ã€‚
- è¯¥ç±»ä¼šloadå‚æ•°ä¸­ä¼ å…¥çš„modelï¼Œå³**yolov5s**
```python

        if pt:  # PyTorch
            model = attempt_load(weights if isinstance(weights, list) else w, device=device, inplace=True, fuse=fuse)
            stride = max(int(model.stride.max()), 32)  # model stride
            names = model.module.names if hasattr(model, 'module') else model.names  # get class names
            model.half() if fp16 else model.float()
            self.model = model  # explicitly assign for to(), cpu(), cuda(), half()
```
# model/YOLO
## Detect
### æµç¨‹

- Detectå±‚ä½œä¸ºæœ€åä¸€å±‚ï¼Œä¾ç„¶ä¼šé€šè¿‡å·ç§¯ä¸ºæ¯ä¸ªcellï¼Œè®¡ç®—å‡ºé¢„æµ‹ç»“æœã€‚`(tx,ty,tw,thï¼Œobjectness,cls_conf)`ã€‚å…¶ä¸­cls_confæ˜¯äº’æ–¥çš„ï¼Œå³å¯ä»¥æœ‰å¤šä¸ªæœ€å¤§å€¼ã€‚detectå±‚ä¸­å¹¶ä¸çŸ¥é“anchorçš„å­˜åœ¨ï¼Œåªæœ‰è®­ç»ƒæ—¶ï¼Œä¼šå€ŸåŠ©anchorå°†è¾“å‡ºè§£ç æˆæ¡†ï¼Œå¹¶ä¸”é€šè¿‡åå‘ä¼ æ’­æ›´æ–°å‚æ•°ã€‚æ¨ç†æ—¶ä¹Ÿä¼šè®¡ç®—å‡ºè§£ç åçš„æ¡†å›ä¼ ã€‚
- trainæ—¶ï¼Œåªæœ‰ç‰¹å¾å›¾çš„è¾“å‡ºx.`x:(bs, na, gridy,gridx,  no)`,å¹¶ä¸”x**æœªè§£ç **ï¼Œè¡¨ç¤ºé¢„æµ‹çš„`(tx,ty,tw,thï¼Œobjectness,cls_conf)`æ²¡æœ‰ä¸anchorå’Œcellçš„åæ ‡ä½œç”¨ã€‚

- å½“æ¨ç†æ¨¡å¼æ—¶ï¼Œè¾“å‡ºå½¢çŠ¶æ˜¯ï¼š`cat((batch_size, na * nx * ny, no),x)`  zæ˜¯**è§£ç **è¿‡åçš„é¢„æµ‹æ¡†ã€‚(ä½¿ç”¨sigmoidå‡½æ•°è§£ç )
```text
é¢„æµ‹å€¼(æ¯ä¸ªanchor): [tx, ty, tw, th]
grid:   cell çš„ä¸­å¿ƒç‚¹åæ ‡
anchor_grid: æ¯ä¸ª cell çš„ anchor box çš„ w å’Œ hï¼ˆç›¸å¯¹åŸå›¾ï¼‰

æœ€ç»ˆé¢„æµ‹æ¡†ï¼ˆx, y, w, hï¼‰ä¸ºï¼š
  x = sigmoid(tx) + grid_x
  y = sigmoid(ty) + grid_y
  w = exp(tw) Ã— anchor_w
  h = exp(th) Ã— anchor_h
```
- height*widthï¼šè¡¨ç¤ºç‰¹å¾å›¾çš„é¢ç§¯ï¼Œè€Œnaï¼šè¡¨ç¤ºæ¯å±‚anchorçš„ä¸ªæ•°ä¸€èˆ¬ä¸ºä¸‰ä¸ªï¼›noï¼šè¡¨ç¤ºanchoré¢„æµ‹çš„æ•°é‡ï¼›
    - æ¯ä¸ªanchoréƒ½ä¼šé¢„æµ‹å‡ºnc+5ä¸ªæ•°å€¼[x, y, w, h, objectness] + [cls1, cls2, ..., cls_nc]ï¼›æˆ‘ä»¬ä¼šæ‰¾å‡º**åŒ¹é…åº¦æœ€é«˜(IOU)çš„anchorç”¨åšground truth**ï¼Œç»§ç»­è®­ç»ƒmodelé€¼è¿‘è¿™ä¸ªé¢„æµ‹æ¡†ï¼›å…¶ä½™éƒ½è¢«è®¤ä¸ºè´Ÿæ ·æœ¬ã€‚å¦‚æœè¯¥ anchor ä¸æŸä¸ªçœŸå®æ¡†åŒ¹é…ï¼ˆIoUè¾ƒé«˜ï¼‰ï¼Œ**å®ƒçš„objectness æ ‡ç­¾ä¸º1**ï¼›
eg:
```perl
(batch_size, na * nx * ny, no)
= (1, 3 * 2 * 2, 8)
= (1, 12, 8)
```
zçš„å…·ä½“è¾“å‡ºå¦‚ä¸‹ï¼š
```python
# å‡è®¾é¢„æµ‹ç»“æœ z çš„å†…å®¹
z = [
    # å›¾åƒ 1ï¼ˆbatch_size=1ï¼‰
    [
        # é”šæ¡† 1 (å¯¹äºç‰¹å¾å›¾ä½ç½® (0,0))
        [x1, y1, w1, h1, conf1, cls1_1, cls1_2, cls1_3],
        # é”šæ¡† 2 (å¯¹äºç‰¹å¾å›¾ä½ç½® (0,0))
        [x2, y2, w2, h2, conf2, cls2_1, cls2_2, cls2_3],
        # é”šæ¡† 3 (å¯¹äºç‰¹å¾å›¾ä½ç½® (0,0))
        [x3, y3, w3, h3, conf3, cls3_1, cls3_2, cls3_3],
        
        # é”šæ¡† 4 (å¯¹äºç‰¹å¾å›¾ä½ç½® (0,1))
        [x4, y4, w4, h4, conf4, cls4_1, cls4_2, cls4_3],
        # é”šæ¡† 5 (å¯¹äºç‰¹å¾å›¾ä½ç½® (0,1))
        [x5, y5, w5, h5, conf5, cls5_1, cls5_2, cls5_3],
        # é”šæ¡† 6 (å¯¹äºç‰¹å¾å›¾ä½ç½® (0,1))
        [x6, y6, w6, h6, conf6, cls6_1, cls6_2, cls6_3],

        # é”šæ¡† 7 (å¯¹äºç‰¹å¾å›¾ä½ç½® (1,0))
        [x7, y7, w7, h7, conf7, cls7_1, cls7_2, cls7_3],
        # é”šæ¡† 8 (å¯¹äºç‰¹å¾å›¾ä½ç½® (1,0))
        [x8, y8, w8, h8, conf8, cls8_1, cls8_2, cls8_3],
        # é”šæ¡† 9 (å¯¹äºç‰¹å¾å›¾ä½ç½® (1,0))
        [x9, y9, w9, h9, conf9, cls9_1, cls9_2, cls9_3],

        # é”šæ¡† 10 (å¯¹äºç‰¹å¾å›¾ä½ç½® (1,1))
        [x10, y10, w10, h10, conf10, cls10_1, cls10_2, cls10_3],
        # é”šæ¡† 11 (å¯¹äºç‰¹å¾å›¾ä½ç½® (1,1))
        [x11, y11, w11, h11, conf11, cls11_1, cls11_2, cls11_3],
        # é”šæ¡† 12 (å¯¹äºç‰¹å¾å›¾ä½ç½® (1,1))
        [x12, y12, w12, h12, conf12, cls12_1, cls12_2, cls12_3]
    ]
]

```
```python
 def forward(self, x):
        z = []  # inference output
        for i in range(self.nl):
            x[i] = self.m[i](x[i])  # conv
            bs, _, ny, nx = x[i].shape  # x(bs,255,20,20) to x(bs,3,20,20,85)
            x[i] = x[i].view(bs, self.na, self.no, ny, nx).permute(0, 1, 3, 4, 2).contiguous()

            if not self.training:  # inference
                if self.dynamic or self.grid[i].shape[2:4] != x[i].shape[2:4]:
                    self.grid[i], self.anchor_grid[i] = self._make_grid(nx, ny, i)

                if isinstance(self, Segment):  # (boxes + masks)
                    xy, wh, conf, mask = x[i].split((2, 2, self.nc + 1, self.no - self.nc - 5), 4)
                    xy = (xy.sigmoid() * 2 + self.grid[i]) * self.stride[i]  # xy
                    wh = (wh.sigmoid() * 2) ** 2 * self.anchor_grid[i]  # wh
                    y = torch.cat((xy, wh, conf.sigmoid(), mask), 4)

                     return x if self.training else (torch.cat(z, 1),) if self.export else (torch.cat(z, 1), x)

```


**anchor**
 å‡è®¾æˆ‘ä»¬è¾“å…¥ä¸€å¼  `640Ã—640` çš„å›¾ç‰‡ï¼Œç»è¿‡å·ç§¯ backbone å’Œ FPN åï¼Œæœ€åä¼šå¾—åˆ°ä¸åŒå°ºåº¦çš„ç‰¹å¾å›¾ï¼Œä¾‹å¦‚ï¼š
|å±‚çº§ï¼ˆheadï¼‰|ç‰¹å¾å›¾å°ºå¯¸|æ¯ä¸ª cell å¯¹åº”åŸå›¾çš„å¤§å°|stride|
|---|---|---|---|
|P3 (small)|80Ã—80|640/80 = 8 â†’ 8Ã—8 åƒç´ |8|
|P4 (medium)|40Ã—40|640/40 = 16 â†’ 16Ã—16 åƒç´ |16|
|P5 (large)|20Ã—20|640/20 = 32 â†’ 32Ã—32 åƒç´ |32|
- è¿™å¼ ç‰¹å¾å›¾ä¸Šçš„æ¯ä¸€ä¸ªä½ç½® `[i, j]`ï¼Œæˆ‘ä»¬å°±å«åšä¸€ä¸ª **cell**ï¼›
- æ¯ä¸ª cell å®é™…ä»£è¡¨äº†åŸå›¾ä¸­ä¸€ä¸ª `stride Ã— stride` çš„åŒºåŸŸã€‚æ‰€ä»¥strideè¶Šå¤§ï¼Œæ¯ä¸ªç‚¹ä»£è¡¨çš„åŒºåŸŸä¹Ÿå°±è¶Šå¤§ï¼Œè§†é‡ä¹Ÿå°±è¶Šå¤§ï¼Œé€‚åˆæ£€æµ‹å¤§ç›®æ ‡ï¼› æ¯ä¸€ä¸ªcelléƒ½é…å¤‡äº†**ä¸€ç»„anchoræ¡†(3ä¸ª)**ï¼Œæœ‰äº›anchorå¾ˆå¤§ï¼Œæ‰€ä»¥cellä¸­çš„gridéƒ½ä¼šäº¤å‰ã€‚
æ¯å±‚éƒ½æœ‰ 3 ä¸ª anchorï¼Œå› æ­¤ï¼š
- P3: 3 Ã— 80 Ã— 80 = **19200** anchor
- P4: 3 Ã— 40 Ã— 40 = **4800**
- P5: 3 Ã— 20 Ã— 20 = **1200**
```python
    anchors:
    # ç‰¹å¾å›¾å°ºå¯¸(w,h), æ³¨é‡ŠæŒ‡çš„æ˜¯ä¸‹é‡‡æ ·ä¸ªæ•°ï¼Œ40 / 8 = 80 Ã— 80
    - [10,13, 16,30, 33,23]  # P3/8
    - [30,61, 62,45, 59,119]  # P4/16
    - [116,90, 156,198, 373,326]  # P5/32
```

- anchor_gridå’Œgrid éƒ½æ˜¯å½’ä¸€åŒ–åçš„ï¼Œå³é™¤ä»¥äº†strideï¼Œç›´åˆ°é¢„æµ‹æ—¶å†ä¹˜å›æ¥ã€‚å…¶ä¸­`grid`ä»£è¡¨äº†ä¸­åºçš„åæ ‡ï¼Œè€Œ`anchor_grid`ä»£è¡¨äº†å®½å’Œé«˜ã€‚

```python
 def _make_grid(self, nx=20, ny=20, i=0, torch_1_10=check_version(torch.__version__, '1.10.0')):
        # iï¼šå½“å‰å±‚ç´¢å¼•ï¼ˆä¾‹å¦‚ P3 æ˜¯ 0ï¼ŒP4 æ˜¯ 1ï¼ŒP5 æ˜¯ 2
        d = self.anchors[i].device
        t = self.anchors[i].dtype
        shape = 1, self.na, ny, nx, 2  # grid shape,2è¡¨ç¤ºä¸­å¿ƒç‚¹åæ ‡
        y, x = torch.arange(ny, device=d, dtype=t), torch.arange(nx, device=d, dtype=t)
        yv, xv = torch.meshgrid(y, x, indexing='ij') if torch_1_10 else torch.meshgrid(y, x)  # torch>=0.7 compatibility
        grid = torch.stack((xv, yv), 2).expand(shape) - 0.5  # add grid offset, i.e. y = 2.0 * x - 0.5
        anchor_grid = (self.anchors[i] * self.stride[i]).view((1, self.na, 1, 1, 2)).expand(shape)
        return grid, anchor_grid
```


## BaseModel
**forward_once**
- çœ‹å½“å‰çš„è¾“å…¥æ˜¯å¦æ¥è‡ªä¸Šä¸€å±‚ï¼Œ`m.f ==-1`è¡¨ç¤ºæ¥è‡ªä¸Šä¸€å±‚ï¼›å¦‚æœä¸æ˜¯æ¥è‡ªä¸Šä¸€å±‚ï¼Œ`m.f`ä»£è¡¨äº†ç¬¬å‡ å±‚(ä¹Ÿå¯èƒ½æ˜¯åˆ—è¡¨)
- yæ˜¯ç”¨æ¥å­˜å‚¨ä¸­é—´å±‚çš„ç»“æœçš„ï¼Œä¹Ÿå°±æ˜¯xã€‚
- å‰©ä¸‹çš„å°±æ˜¯æ­£å¸¸è°ƒç”¨modelï¼ŒæŒ‡çš„æ˜¯æŠŠæ‰€æœ‰å±‚éƒ½forwardä¸€éã€‚å½“modelå†™æˆmodellistå°±å¯ä»¥ç”¨forå¾ªç¯å¾ªç¯ä¸€é.
```python
 for m in self.model:
            if m.f != -1:  # if not from previous layer
                x = y[m.f] if isinstance(m.f, int) else [x if j == -1 else y[j] for j in m.f]  # from earlier layers
                x = m(x)  # run
```
```python
 self.model = nn.ModuleList([
            nn.Conv2d(3, 16, 3, padding=1),
            nn.ReLU(),
            nn.Conv2d(16, 32, 3, padding=1),
            nn.ReLU()
        ])
```
```text
è¾“å…¥ x
   â†“
for m in self.model:
    x = é€‰å–è¾“å…¥ (ä»yæˆ–ä¸Šä¸€å±‚)
    if profile: åˆ†æ FLOPs + æ—¶é—´
    x = m(x)  # æ­£å¼æ‰§è¡Œ
    if m.i in save: y.append(x)
    if visualize: ç”»å›¾
   â†“
è¾“å‡º xï¼ˆæœ€åä¸€å±‚ï¼‰

```



## DetectionModel
DetectionModel æ˜¯**YOLOv5** çš„å®Œæ•´ç»“æ„ï¼Œæ˜¯ä½ è®­ç»ƒ/æ¨ç†ç”¨çš„æ¨¡å‹ç±»,è®­ç»ƒçš„æ˜¯å®ƒã€ä¿å­˜çš„æ˜¯å®ƒã€å¯¼å‡º ONNX/torchscript ä¹Ÿæ˜¯å®ƒã€‚å®ƒä¼šè§£æyamlæ–‡ä»¶ï¼Œå¾—å‡ºæ•´ä¸ªYOLOçš„æ¨¡å‹ç»“æ„**Backbone + Neck + Detect**
`model[-1]`ï¼šè¡¨ç¤ºæœ€åå±‚ï¼Œ-1çš„è¯ä»æœ«å°¾å¼€å§‹è®¡æ•°ã€‚
- æœ‰ä¸¤ç§forward()å‡½æ•°ï¼Œä¸€ç§æ™®é€šç‰ˆæœ¬çš„.
**åŠ å¼ºforward**
ä¸€ç§å¯¹ç‰¹å¾å›¾æ”¾ç¼©åŠ æ—‹è½¬ä¹‹åå†å¤„ç†çš„å›¾ã€‚å¤„ç†å®Œçš„anchoræ¡†æœ‰å¾ˆå¤šé‡å¤çš„ï¼Œè¿˜éœ€è¦è£å‰ªã€‚
```python
   def _forward_augment(self, x):
        img_size = x.shape[-2:]  # height, width
        s = [1, 0.83, 0.67]  # scalesï¼Œæ–¹æ³•ç¼©å°å¤„ç†
        f = [None, 3, None]  # flips (2-ud, 3-lr)ï¼Œç¿»è½¬å¤„ç†
        y = []  # outputs
        for si, fi in zip(s, f):
            xi = scale_img(x.flip(fi) if fi else x, si, gs=int(self.stride.max()))
            yi = self._forward_once(xi)[0]  # forward
            # cv2.imwrite(f'img_{si}.jpg', 255 * xi[0].cpu().numpy().transpose((1, 2, 0))[:, :, ::-1])  # save
            yi = self._descale_pred(yi, fi, si, img_size)
            y.append(yi)
        y = self._clip_augmented(y)  # clip augmented tails
        return torch.cat(y, 1), None  # augmented inference, train
```

**åˆå§‹åŒ–åç½®**
- ä¸æ˜¯è¿™æ˜¯çœŸçœ‹ä¸æ‡‚äº†ï¼Œå‡è®¾åŸå§‹å›¾åƒå¹³å‡æœ‰8ä¸ªç›®æ ‡ï¼›ä»¥åŠæ¯ä¸ªç±»çš„æ¦‚ç‡å¤§çº¦ä¸º$\frac{0.6}{nc}$
```python
  def _initialize_biases(self, cf=None):  # initialize biases into Detect(), cf is class frequency
        # https://arxiv.org/abs/1708.02002 section 3.3
        # cf = torch.bincount(torch.tensor(np.concatenate(dataset.labels, 0)[:, 0]).long(), minlength=nc) + 1.
        m = self.model[-1]  # Detect() module
        for mi, s in zip(m.m, m.stride):  # from
            b = mi.bias.view(m.na, -1)  # conv.bias(255) to (3,85)
            b.data[:, 4] += math.log(8 / (640 / s) ** 2)  # obj (8 objects per 640 image)
            b.data[:, 5:5 + m.nc] += math.log(0.6 / (m.nc - 0.99999)) if cf is None else torch.log(cf / cf.sum())  # cls
            mi.bias = torch.nn.Parameter(b.view(-1), requires_grad=True)

```
## parse_model
- è¿™ä¸ªç¡®å®å¯ä»¥å…ˆä¸å­¦ï¼Œåé¢å†å­¦å³å¯ã€‚
**è¾“å…¥**:
`def parse_model(d, ch)`dï¼šæ˜¯ model.yaml æ–‡ä»¶è§£æå‡ºæ¥çš„å­—å…¸ï¼ˆdictï¼‰ï¼ŒåŒ…å«äº† backbone, head, anchors, depth_multiple, width_multiple, nc ç­‰;
chï¼šæ˜¯æ¯ä¸ªæ¨¡å—çš„è¾“å…¥é€šé“åˆ—è¡¨ï¼ˆé€šå¸¸ä» [3] å¼€å§‹ï¼Œå³ RGB ä¸‰é€šé“ï¼‰ã€‚

**è¾“å‡º**
`return nn.Sequential(*layers), sorted(save)`è¿”å›ä¸€ä¸ª nn.Sequential æ¨¡å‹å’Œéœ€è¦ä¿å­˜ç‰¹å¾å›¾çš„å±‚ç´¢å¼•åˆ—è¡¨ï¼ˆé€šå¸¸ç”¨äºåç»­æ£€æµ‹å¤´ä½¿ç”¨ï¼‰ã€‚

```text
           model.yaml
                â†“
         parse_model(d, ch)
                â†“
  éå† backbone å’Œ head æ¨¡å—å®šä¹‰
                â†“
    æ¯å±‚æ„é€  m_(module)ï¼Œç¡®å®š c2ï¼ˆè¾“å‡ºé€šé“ï¼‰
                â†“
       åŠ¨æ€åˆ›å»º PyTorch æ¨¡å—ï¼ˆm_ï¼‰
                â†“
   è®°å½• fromã€indexã€å‚æ•°æ•°ã€è¾“å‡ºé€šé“æ•°
                â†“
          æ„é€  nn.Sequential æ¨¡å‹
                â†“
    â†’ è¿”å› æ¨¡å‹ç»“æ„ + ä¸­é—´å±‚ä¿å­˜ç´¢å¼•ï¼ˆsaveï¼‰

```



### YOLOv5s
**backbone:**
- ä»è¾“å…¥å›¾åƒä¸­æå–ç‰¹å¾
**head:**
- èåˆç‰¹å¾å›¾ï¼Œå¹¶å‡†å¤‡ç›®æ ‡æ£€æµ‹çš„ä¸åŒå°ºåº¦è¾“
- å®ƒå°±åƒâ€œè§†è§‰é€»è¾‘æ¨ç†ä¸­å¿ƒâ€ï¼ŒæŠŠä»ä¸åŒä½ç½®å­¦åˆ°çš„å›¾åƒçŸ¥è¯†æ‹¼æ¥èµ·æ¥ï¼Œå½¢æˆå¯¹ç›®æ ‡çš„â€œç†è§£â€ã€‚èåˆç‰¹å¾å›¾ï¼Œå¹¶å‡†å¤‡ç›®æ ‡æ£€æµ‹çš„ä¸åŒå°ºåº¦è¾“

å‡è®¾ä½ è¦æ£€æµ‹å›¾ä¸­çš„çŒ«ï¼š

- Backbone æå–äº†â€œçŒ«è€³æœµâ€â€œçŒ«æ¯›â€â€œè½®å»“â€ç­‰å›¾åƒä½çº§ç‰¹å¾ï¼›
- Head æŠŠä¸åŒå±‚çš„ç‰¹å¾æ‹¼åœ¨ä¸€èµ·ï¼Œç†è§£è¿™æ˜¯â€œçŒ«çš„æ•´ä½“â€ï¼›
- Detect è¾“å‡ºé¢„æµ‹æ¡†ï¼šâ€œè¿™é‡Œæœ‰åªçŒ«ï¼Œæ¦‚ç‡ 0.92ï¼Œæ¡†çš„ä½ç½®æ˜¯ (x, y, w, h)â€ã€‚




# Train
Trainçš„ç›®çš„ä¸ºä½¿model**æ›´æ–°å„ç§å‚æ•°**ï¼Œå­¦ä¼šæå–éœ€è¦è¯†åˆ«çš„å›¾åƒçš„**ç‰¹å¾**ï¼Œæœ€ç»ˆèƒ½ç‹¬ç«‹åˆ¤æ–­å‡ºå›¾åƒä¸­éœ€è¦æ¡†å‡ºæ¥çš„éƒ¨åˆ†ã€‚
ä»¥ä¸‹ä¸ºTrainçš„**å…·ä½“æµç¨‹**ï¼š
- é¦–å…ˆï¼ŒTrainå‰éœ€è¦loadæ•°æ®å’Œmodelï¼Œä»¥åŠå®šä¹‰å¥½loss function, optimizer, schedulerï¼›è¿˜éœ€è¦warm upã€‚dataloaderä¼šå¾—åˆ°`(imgs, targets, paths, _)`,targetsä¸º`[image_index, class, x_center, y_center, width, height]ï¼ˆå…¨æ˜¯å½’ä¸€åŒ–åæ ‡ï¼‰`ï¼Œå³æˆ‘ä»¬ä½¿ç”¨çš„labelsã€‚
- å…¶æ¬¡,å¼€å§‹æ—¶modelä¼šéšæœºé¢„æµ‹å‡ºæ¯ä¸ªcellä¸­çš„prediton(offset)ï¼Œpredictionçš„å¤§å°ä¸º`[batch_size, na, grid_x,grid_y, no ]`
- æ¥ç€ï¼Œæˆ‘ä»¬è®¡ç®—lossï¼Œé€‰æ‹©ä¸ç›®æ ‡æ¡†æ¥è¿‘çš„anchorä¸ºåŸºç‚¹ï¼Œè¿™æ ·modelå­¦ä¹ çš„éš¾åº¦è¾ƒå°(å¯èƒ½å¤šä¸ªanchorå¯¹ä¸€ä¸ªtarget)ã€‚æ­£æ ·æœ¬ objectnessçš„å­¦ä¹ ç›®æ ‡ä¸ºpboxå’Œtboxçš„iou(å› ä¸ºç›¸äº¤é¢ç§¯ä»£è¡¨äº†æˆ‘ä»¬å¯¹è¿™é‡Œæ˜¯å¦æœ‰ç›®æ ‡çš„ä¿¡å¿ƒ)ï¼Œè´Ÿæ ·æœ¬objectnessçš„å­¦ä¹ ç›®æ ‡ä¸º0ï¼›boxçš„å­¦ä¹ ç›®æ ‡ä¸ºtbox(ç›®æ ‡boxç›¸å¯¹äºé€‰ä¸­cellçš„offset)ï¼›classçš„å­¦ä¹ ç›®æ ‡ä¸ºtargetçš„class(æ¯ä¸ªpredictionåªå¯¹åº”ä¸€ä¸ªclassï¼Œå…¶ä»–classçš„æ¦‚ç‡éƒ½ä¸º0)ã€‚
- å†æ¬¡æˆ‘ä»¬ä¼šé€šè¿‡åå‘ä¼ æ’­ï¼Œä¼ æ’­æ¢¯åº¦ï¼Œæ›´æ–°å‚æ•°ã€‚
- Remarkï¼šYOLOä¸­ä½¿ç”¨çš„æ˜¯æ··åˆç²¾åº¦è®­ç»ƒ(AMP)ï¼Œå¤§éƒ¨åˆ†æƒ…å†µä½¿ç”¨FP16ï¼Œå¯¹ç²¾åº¦è¦æ±‚é«˜çš„æ“ä½œ(loss`scaler.scale(loss).backward()`)ï¼Œä¿ç•™FP32ï¼Œè¿™æ ·å¯ä»¥èŠ‚çº¦è®¡ç®—èµ„æº.ä¸ºä»€ä¹ˆä¸ä¼šå‡ºç°æ¢¯åº¦æ¶ˆå¤±å‘¢ï¼Ÿè®¡ç®—lossæ—¶ï¼Œæˆ‘ä»¬ä½¿ç”¨float32ï¼Œæ—¢ä¸ä¼šæ¢¯åº¦æ¶ˆå¤±(lossä¹˜ä»¥1024)ï¼Œä¹Ÿä¸ä¼šæ¢¯åº¦çˆ†ç‚¸(åŸæœ¬æ˜¯FP16ï¼Œç°åœ¨æ˜¯FP32).å¹¶ä¸”æ›´æ–°æƒé‡æ—¶ï¼Œæ¢¯åº¦ä¼šé™¤ä»¥1024ï¼Œä¸”ä¼šé™åˆ¶æ¢¯åº¦å¤§å°ï¼Œé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸ã€‚
- Remark:YOLO ä½¿ç”¨æŒ‡æ•°æ»‘åŠ¨å¹³å‡ï¼ˆEMAï¼‰ç»´æŠ¤ä¸€ä»½æ¨¡å‹çš„å¹³æ»‘ç‰ˆæœ¬ã€‚éšç€è®­ç»ƒè¿­ä»£æ¬¡æ•°å¢åŠ ï¼ŒEMA å¯¹å½“å‰æ¨¡å‹å‚æ•°çš„æ›´æ–°å¹…åº¦é€æ¸å‡å°ï¼Œæ›´ä¾èµ–è¿‡å»ç´¯ç§¯çš„å†å²ä¿¡æ¯ï¼Œä»è€Œä½¿æ¨¡å‹åœ¨è¯„ä¼°æ—¶æ›´åŠ ç¨³å®šï¼Œé¿å…å› ç¬æ—¶æ³¢åŠ¨å¯¼è‡´æ€§èƒ½ä¸ç¨³å®šã€‚
- æœ€åï¼Œæˆ‘ä»¬ä¼šä½¿ç”¨valéªŒè¯modelçš„åŠŸæ•ˆï¼Œå…·ä½“å¯¹ä¸åŒçš„valçš„ç»“æœä½¿ç”¨ä¸åŒçš„æƒé‡ï¼Œå¹¶ä¸”ä½¿ç”¨`fitness`å®šé‡ã€‚æˆ‘ä»¬ä¼šè®°å½•ä¸‹æœ€é«˜çš„fitnesså¯¹åº”çš„modelå‚æ•°ï¼Œå³`best.pt`

```text
Train epoch
â†“
Update LR scheduler
â†“
Update EMA model å±æ€§
â†“
éªŒè¯é›†è¯„ä¼° (validate)
â†“
æ›´æ–° best mAPï¼ˆfitnessï¼‰
â†“
Early stopping æ£€æŸ¥
â†“
Callbacks æ—¥å¿—è®°å½•

```

## Loss
`class Computeloss`
ç”¨äºè®¡ç®—æŸå¤±,é¦–å…ˆæˆ‘ä»¬è‚¯å®šä¸ç”¨æ‰€æœ‰çš„predictionè®¡ç®—æŸå¤±ï¼Œæˆ‘ä»¬å…ˆæŒ‘é€‰**é€‚åˆå­¦ä¹ **çš„anchorå’Œcellã€‚
- `build_targets(self, p, targets)`:æ‰¾å‡ºæ¯”è¾ƒé€‚åˆç”¨äºå­¦ä¹ (å°ºå¯¸ç­›é€‰è¾ƒé€‚åˆ)`j = torch.max(r, 1 / r).max(2)[0] < anchor_t`çš„anchoræ¡†çš„å¤§å°å’Œcellçš„idxã€‚(pçš„ä½œç”¨æ˜¯æä¾›cellçš„å¤§å°)ï¼Œ`return tcls, tbox, indices, anch`.
Remark:æˆ‘ä»¬æ˜¯é’ˆå¯¹äºå›¾ä¸­çš„æ¯ä¸ªlabelé€‰æ‹©çš„anchorå’Œå¯¹åº”çš„cellï¼Œæ‰€ä»¥å¯èƒ½å‡ºç°**å¤šä¸ªanchorså¯¹åº”ä¸€ä¸ªlabel**ã€‚
    - tcls:ä¸ºclassï¼Œä¸€èˆ¬å±‚æ•°ä¸º3ï¼ŒåŒ…å«è¯¥å±‚æ‰€æœ‰æ­£æ ·æœ¬çš„ç±»åˆ«idï¼Œä»target classä¸­é€‰æ‹©å‡ºæ¥ã€‚ç±»åˆ«æ ¹æ®targetä¸­çš„labelé€‰æ‹©å‡ºæ¥ï¼Œ**æ¯ä¸ªanchoréœ€è¦å­¦ä¹ boxå’Œå¯¹ä¸€ä¸ªçš„label**
    - tboxï¼šä¸ºç›®æ ‡æ¡†åœ¨å½“å‰cellçš„offsetä¸å®½é«˜`[x_offset, y_offset, width, height]`
    - indicesï¼š`[b,a,gj,gi]`è¡¨ç¤ºimgidx,anchoridx,gridxidx, gridyidx.
    - anchï¼šè¡¨ç¤ºanchorçš„å¤§å°`[width,height]`ã€‚
```python
def build_targets(self, p, targets):
        # Build targets for compute_loss(), input targets(image,class,x,y,w,h)
 # Matches
                r = t[..., 4:6] / anchors[:, None]  # wh ratio
                j = torch.max(r, 1 / r).max(2)[0] < self.hyp['anchor_t'] 
 # Append
            indices.append((b, a, gj.clamp_(0, shape[2] - 1), gi.clamp_(0, shape[3] - 1)))  # image, anchor, grid
            tbox.append(torch.cat((gxy - gij, gwh), 1))  # box
            anch.append(anchors[a])  # anchors
            tcls.append(c)  # class

        return tcls, tbox, indices, anch

```
- ä¸€å…±æœ‰ä¸‰ç§æŸå¤±ï¼Œ**classï¼Œbox(ä½ç½®æŸå¤±)**,**objectness(ç›®æ ‡å­˜åœ¨æŸå¤±)**,åªæœ‰è¢«build_targetsé€‰ä¸­çš„prediction`  pxy, pwh, _, pcls = pi[b, a, gj, gi].split((2, 2, 1, self.nc), 1)  `ä¼šè®¡ç®—classå’ŒboxæŸå¤±ã€‚
- box lossé‡‡å–`pbox,tbox`çš„iou lossçš„å¹³å‡å€¼`lbox += (1.0 - iou).mean`
```python
 pbox = torch.cat((pxy, pwh), 1)  # predicted box
                iou = bbox_iou(pbox, tbox[i], CIoU=True).squeeze()  # iou(prediction, target)
                lbox += (1.0 - iou).mean()  # iou loss
```
- objectness loss é‡‡å–**äº¤å‰ç†µ**ï¼Œ**æ²¡æœ‰è¢«é€‰ä¸­çš„predctionçš„objectnessä¸º0**ã€‚æ²¡æœ‰è¢«é€‰ä¸­çš„anchorä¹Ÿéœ€è¦å­¦ä¹ ç›®æ ‡æ˜¯å¦å­˜åœ¨è¿™ä»¶äº‹æƒ…ã€‚å¹¶ä¸”æˆ‘ä»¬å¸Œæœ›é€‰æ‹©çš„predctionæœ€åå¾—å‡ºçš„confå’Œ`pbox,tbox`çš„iouä¸€è‡´
```python
 # Objectness
                iou = iou.detach().clamp(0).type(tobj.dtype)
                if self.sort_obj_iou:
                    j = iou.argsort()
                    b, a, gj, gi, iou = b[j], a[j], gj[j], gi[j], iou[j]
                if self.gr < 1:
                    iou = (1.0 - self.gr) + self.gr * iou
                tobj[b, a, gj, gi] = iou  # iou ratio
obji = self.BCEobj(pi[..., 4], tobj)
            lobj += obji * self.balance[i]  # obj loss
```
- label smoothing: æ ‡ç­¾å¹³æ»‘ï¼Œå°†0å’Œ1smoothingï¼Œæé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ï¼Œå¹¶ä¸”ä½¿modelå­¦ä¹ å¾—ä¸ä¼šè¿‡äºç»å¯¹ã€‚
- class loss: é¢„æµ‹å‡ºçš„lossä¸ç›®æ ‡lossçš„äºŒåˆ†ç±»äº¤å‰ç†µ(åªå¯¹æ­£æ ·æœ¬è¿›è¡Œ)ï¼Œå¹¶ä¸”æ˜¯é’ˆå¯¹ç´¢å¼•è¿›è¡Œçš„,æˆ‘ä»¬å¸Œæœ›è®­ç»ƒå‡ºæ¥åªæœ‰`tcls[i]`ä¸­çš„ç±»åˆ«è¢«é¢„æµ‹å‡ºæ¥ã€‚`tcls[i]`è¡¨ç¤ºçš„æ˜¯ç¬¬iå±‚ä¸­ï¼Œé€‰ä¸­çš„anchorå¯¹åº”çš„çœŸå®ç±»åˆ«(å…±æœ‰nç§)ï¼Œä¸”æˆ‘ä»¬é€‰å–çš„pclsæ¯å±‚ä¹Ÿåªæœ‰nç§ã€‚
remarkï¼šåªæœ‰ä¸€ç±»çš„classå°±ä¸éœ€è¦è¿™ä¸ªlossäº†ï¼›ä¸”lossé‡Œçš„å¾ªç¯é’ˆå¯¹çš„æ˜¯anchorçš„å±‚æ•°(3å±‚)ã€‚
```python
 for i, pi in enumerate(p): 
    # layer index, layer predictions
       # Classification
                if self.nc > 1:  # cls loss (only if multiple classes)
                    t = torch.full_like(pcls, self.cn, device=self.device)  # targets
                    t[range(n), tcls[i]] = self.cp
                    lcls += self.BCEcls(pcls, t)  # BCE
```

- `pi[b, a, gj, gi]`:å› ä¸ºxè¾“å‡ºçš„å½¢çŠ¶ä¸º`[batch,na,grid_y,grid_x,no]`
```python
pxy, pwh, _, pcls = pi[b, a, gj, gi].split((2, 2, 1, self.nc), 1)  # target-subset of predictions

                # Regression
                pxy = pxy.sigmoid() * 2 - 0.5
                pwh = (pwh.sigmoid() * 2) ** 2 * anchors[i]
                pbox = torch.cat((pxy, pwh), 1)  # predicted box
                iou = bbox_iou(pbox, tbox[i], CIoU=True).squeeze()  # iou(prediction, target)
                lbox += (1.0 - iou).mean()  # iou loss

                # Objectness
                iou = iou.detach().clamp(0).type(tobj.dtype)

# è®¡ç®—çš„æ˜¯æ€»æŸå¤±*bs
# åä¸€ä¸ªè¾“å‡ºæŠŠä»–ä»¬æ‹¼æ¥æˆä¸€ä¸ªå¼ é‡æ˜¯ä¸ºäº†è¾“å‡ºï¼Œæ‰€æœ‰ä½¿ç”¨.detach()ï¼Œä¸è¿­ä»£æ¢¯åº¦ã€‚ 
        return (lbox + lobj + lcls) * bs, torch.cat((lbox, lobj, lcls)).detach()
```








## EMA
- (æŒ‡æ•°åŠ æƒç§»åŠ¨å¹³å‡)æ˜¯ä¸€ç§å¸¸ç”¨çš„æŠ€æœ¯ï¼Œç”¨äºå¹³æ»‘å’Œç¨³å®šæ¨¡å‹è®­ç»ƒè¿‡ç¨‹ä¸­çš„å‚æ•°æ›´æ–°,æ™®éç”¨äºæ¨ç†modelã€‚
- é¦–å…ˆï¼Œå®ƒä¸åŸæ¨¡å‹å…±äº«ç»“æ„ï¼Œä½†å‚æ•°æ˜¯ç‹¬ç«‹çš„å‰¯æœ¬ï¼Œä¸ä¼šå‚ä¸æ¢¯åº¦è®¡ç®—(å…³é—­EMAçš„å‚æ•°çš„æ¢¯åº¦æ›´æ–°).
```python
 def __init__(self, model, decay=0.9999, tau=2000, updates=0):
        # Create EMA
        self.ema = deepcopy(de_parallel(model)).eval()  # FP32 EMA
        self.updates = updates  # number of EMA updates
        self.decay = lambda x: decay * (1 - math.exp(-x / tau))  # decay exponential ramp (to help early epochs)
        for p in self.ema.parameters():
            p.requires_grad_(False)
```
- åŸºæœ¬çš„æ›´æ–°å…¬å¼ä¸ºï¼š$\hat{Î¸}_tâ€‹=dâ‹…\hat{Î¸}_(tâˆ’1)â€‹+(1âˆ’d)â‹…\hat{Î¸}_tâ€‹$ã€‚éšç€updateçš„å¢åŠ ï¼Œè¡°å‡å› å­dä¸æ–­å¢å¤§ï¼Œdè¶Šå¤§ï¼Œè¿‡å»EMAçš„è®¡ç®—å æ¯”è¶Šå¤§ï¼Œå½“å‰çš„ä¸»æ¨¡å‹å‚æ•°å æ¯”å°±è¶Šå°ã€‚ `v` æ˜¯ EMA æ¨¡å‹ä¸­çš„æŸä¸€ä¸ªå‚æ•°å¼ é‡,ä¸»æ¨¡å‹å‚æ•°å°±æ˜¯ `msd[k]`ã€‚è®©æ¨¡å‹å‰æœŸå¿«é€Ÿèåˆï¼ŒåæœŸé€
```python
number of EMA updates
        self.decay = lambda x: decay * (1 - math.exp(-x / tau))  # decay exponential ramp (to help early epochs)
        self.updates += 1
        d = self.decay(self.updates)

        for k, v in self.ema.state_dict().items():
            if v.dtype.is_floating_point:  # true for FP16 and FP32
                v *= d
                v += (1 - d) * msd[k].detach()
```

```python
 
    def update(self, model):
        # Update EMA(Exponential Moving Average)parameters
        self.updates += 1
        d = self.decay(self.updates)

        msd = de_parallel(model).state_dict()  # model state_dictï¼Œè·å–æ‰€æœ‰å‚æ•°çš„æƒé‡ã€‚
        for k, v in self.ema.state_dict().items():
            if v.dtype.is_floating_point:  # true for FP16 and FP32
                v *= d
                v += (1 - d) * msd[k].detach()
        # assert v.dtype == msd[k].dtype == torch.float32, f'{k}: EMA {v.dtype} and model {msd[k].dtype} must be FP32'

    def update_attr(self, model, include=(), exclude=('process_group', 'reducer')):
        # Update EMA attributes
        copy_attr(self.ema, model, include, exclude)
```


## AMP
- æ··åˆç²¾åº¦è®­ç»ƒï¼Œæ··åˆç²¾åº¦æŒ‡çš„æ˜¯æ··åˆfloat16å’Œfloat32ç²¾åº¦ã€‚ä¸ºäº†èŠ‚çœå†…å­˜å’ŒåŠ é€Ÿï¼Œé‡‡ç”¨float16ï¼Œä½†float16çš„ç²¾åº¦å¤ªä½ï¼Œä¸ºäº†é˜²æ­¢æ¢¯åº¦underflowï¼Œéœ€è¦ä¸´æ—¶æŠŠlossæ”¾å¤§ã€‚å†ä¹‹åï¼Œå†æŠŠæ¢¯åº¦ç¼©å›æ¥ï¼Œå°±å¯ä»¥æ­£å¸¸æ›´æ–°äº†ã€‚
- backward()ç”¨äºè®¡ç®—æ¢¯åº¦;`scaler.step(optimizer)`ç”¨äºæ›´æ–°æ¢¯åº¦
- éœ€è¦é…åˆ`autocast`ä½¿ç”¨ï¼Œautocast æ˜¯ PyTorch ä¸­ç”¨äº è‡ªåŠ¨æ··åˆç²¾åº¦è®­ç»ƒ çš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨(è‡ªåŠ¨å†³å®šå“ªäº›è®¡ç®—ä½¿ç”¨float16å’Œfloat32)
> - å‰å‘ä¼ æ’­ 16
> - loss 32ï¼Œè¦æ±‚ç²¾åº¦é«˜
> - åå‘ä¼ æ’­ 16ï¼Œä½†æ˜¯è¦ä¹˜ä»¥ä¸€ä¸ªscaler
- æ”¾å¤§ä¸ºä»€ä¹ˆä¸ä¼šå¯¼è‡´æ¢¯åº¦çˆ†ç‚¸ï¼šå› ä¸ºæˆ‘ä»¬ä¼ æ’­æ—¶è™½ç„¶æ‰©å¤§äº†ï¼Œä½†æ˜¯æˆ‘ä»¬æ›´æ–°å‚æ•°æ—¶ç¼©å°å›æ¥äº†ï¼Œè¿˜å°†æœ€å¤§å€¼è£å‰ªè‡³10ï¼Œæ•…ä¸ä¼šæ¢¯åº¦çˆ†ç‚¸ã€‚
```python
 with torch.cuda.amp.autocast(amp):
                pred = model(imgs)  # forward
                loss, loss_items = compute_loss(pred, targets.to(device))  # loss scaled by batch_size
                if RANK != -1:
                    loss *= WORLD_SIZE  # gradient averaged between devices in DDP mode
                if opt.quad:
                    loss *= 4.

            # Backward
            scaler.scale(loss).backward()

            # Optimize - https://pytorch.org/docs/master/notes/amp_examples.html
            if ni - last_opt_step >= accumulate:
                scaler.unscale_(optimizer)  # unscale gradients
                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10.0)  # clip gradients
                scaler.step(optimizer)  # optimizer.step
                scaler.update()
                optimizer.zero_grad()
                if ema:
                    ema.update(model)
                last_opt_step = ni
```

## checkpoint
```python
ckpt = {
    'epoch': epoch,                         # å½“å‰è®­ç»ƒåˆ°äº†ç¬¬å‡ ä¸ª epoch
    'best_fitness': best_fitness,           # å½“å‰ä¸ºæ­¢çš„æœ€ä½³æ¨¡å‹æ€§èƒ½ï¼ˆé€šå¸¸åŸºäº mAPï¼‰
    'model': deepcopy(de_parallel(model)).half(),  # å½“å‰æ¨¡å‹çš„æƒé‡ï¼ˆæ³¨æ„æ˜¯åŠç²¾åº¦ float16ï¼‰
    'ema': deepcopy(ema.ema).half(),        # EMA å¹³æ»‘åçš„æ¨¡å‹æƒé‡ï¼ˆä¹Ÿæ˜¯ float16ï¼‰
    'updates': ema.updates,                 # EMA çš„æ›´æ–°æ¬¡æ•°ï¼ˆå…³é”®ï¼‰
    'optimizer': optimizer.state_dict(),    # å½“å‰ä¼˜åŒ–å™¨çš„çŠ¶æ€ï¼ˆåŒ…æ‹¬åŠ¨é‡ã€å­¦ä¹ ç‡ç­‰ï¼‰
    'opt': vars(opt),                       # å½“å‰è®­ç»ƒç”¨çš„å‚æ•°è®¾ç½®ï¼ˆå‘½ä»¤è¡Œå‚æ•°ï¼‰
    'git': GIT_INFO,                        # å½“å‰ä»£ç ä»“åº“çš„ Git ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
    'date': datetime.now().isoformat()      # ä¿å­˜æ—¶é—´æˆ³
}

```

## Evaluation
- å…ˆé€šè¿‡valuationè®¡ç®—å‡ºpï¼ŒRï¼ŒMAPç­‰ï¼Œå†é€šè¿‡`fitness`å‡½æ•°è®¡ç®—å‡ºå…·ä½“çš„å¾—åˆ†.æ¯”è¾ƒå½“å‰ fitness å’Œå†å²æœ€é«˜ fitnessï¼š

å¦‚æœå½“å‰ fitness é«˜äºä¹‹å‰çš„æœ€é«˜å€¼ï¼Œå°±æ›´æ–°ä¿å­˜â€œæœ€ä½³æ¨¡å‹æƒé‡â€ï¼ˆbest model weightsï¼‰ã€‚å¦åˆ™ä¸ä¿å­˜ï¼Œç»§ç»­è®­ç»ƒã€‚
```python
torch.save(ckpt, last)
                if best_fitness == fi:
                    torch.save(ckpt, best)
```
```python
# Update best mAP
def fitness(x):
    # Model fitness as a weighted combination of metrics
    w = [0.0, 0.0, 0.1, 0.9]  # weights for [P, R, mAP@0.5, mAP@0.5:0.95]
    return (x[:, :4] * w).sum(1)
            fi = fitness(np.array(results).reshape(1, -1))  # weighted combination of [P, R, mAP@.5, mAP@.5-.95]
            stop = stopper(epoch=epoch, fitness=fi)  # early stop check
            if fi > best_fitness:
                best_fitness = fi
```



## save model
```python
# Save model
            if (not nosave) or (final_epoch and not evolve):  # if save
                ckpt = {
                    'epoch': epoch,
                    'best_fitness': best_fitness,
                    'model': deepcopy(de_parallel(model)).half(),
                    'ema': deepcopy(ema.ema).half(),
                    'updates': ema.updates,
                    'optimizer': optimizer.state_dict(),
                    'opt': vars(opt),
                    'git': GIT_INFO,  # {remote, branch, commit} if a git repo
                    'date': datetime.now().isoformat()}
```

##  Multi-scale
- YOLOv5ä¼šåœ¨è®­ç»ƒæ—¶åŠ¨æ€è°ƒæ•´å›¾ç‰‡å°ºå¯¸ï¼Œæé«˜modelçš„robust(ä¹Ÿå¯ä»¥é€‚ç”¨äºå…¶ä»–model)
```python
# Multi-scale
if opt.multi_scale:
    sz = random.randrange(imgsz * 0.5, imgsz * 1.5 + gs) // gs * gs  # size
    sf = sz / max(imgs.shape[2:])  # scale factor
    if sf != 1:
        ns = [math.ceil(x * sf / gs) * gs for x in imgs.shape[2:]]  # new shape (stretched to gs-multiple)
        imgs = nn.functional.interpolate(imgs, size=ns, mode='bilinear', align_corners=False)

```
## Optimizer
- å‰é¢çš„ä»£ç åœ¨å¤„ç†å°batchçš„æƒ…å†µï¼Œé˜²æ­¢batchè¿‡å°å¯¼è‡´ç²¾åº¦è¿‡ä½ã€‚
```python
 # Optimizer
    nbs = 64  # nominal batch size
    accumulate = max(round(nbs / batch_size), 1)  # accumulate loss before optimizing
    hyp['weight_decay'] *= batch_size * accumulate / nbs  # scale weight_decay
    optimizer = smart_optimizer(model, opt.optimizer, hyp['lr0'], hyp['momentum'], hyp['weight_decay'])
```
```python
def smart_optimizer(model, name='Adam', lr=0.001, momentum=0.9, decay=1e-5):

    if name == 'Adam':
        optimizer = torch.optim.Adam(g[2], lr=lr, betas=(momentum, 0.999))  # adjust beta1 to momentum
    elif name == 'AdamW':
        optimizer = torch.optim.AdamW(g[2], lr=lr, betas=(momentum, 0.999), weight_decay=0.0)
    elif name == 'RMSProp':
        optimizer = torch.optim.RMSprop(g[2], lr=lr, momentum=momentum)
    elif name == 'SGD':
        optimizer = torch.optim.SGD(g[2], lr=lr, momentum=momentum, nesterov=True)
    else:
        raise NotImplementedError(f'Optimizer {name} not implemented.')
```


## scheduler
[Pytorch scheduler] (https://docs.pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.LambdaLR.html)
- ä½™å¼¦é€€ç«æˆ–è€…çº¿æ€§é€€ç«å‡½æ•°ã€‚
- scheduleråªæ”¹å˜å­¦ä¹ ç‡è¿™ä¸€ä¸ªå‚æ•°
- `lrf`:learning rate final
```python
# Scheduler
if opt.cos_lr:
    lf = one_cycle(1, hyp['lrf'], epochs)  # cosine 1->hyp['lrf']
else:
    lf = lambda x: (1 - x / epochs) * (1.0 - hyp['lrf']) + hyp['lrf']  # linear
scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lf)  # plot_lr_scheduler(optimizer, scheduler, epochs)
```

```python
 scheduler.step()
```

# detect
- æ¯å¼ å›¾ç‰‡ä¼šç»è¿‡ä¸€æ¬¡detectï¼Œæ‰¾å‡ºå­˜åœ¨çš„ç›®æ ‡
**warm up**
- é€šè¿‡ä¸€æ¬¡æ¨ç†è¿›è¡Œé¢„çƒ­çš„ä¸»è¦ç›®çš„æ˜¯ä¸ºäº†**ä¼˜åŒ–ç¡¬ä»¶å’Œè½¯ä»¶çš„åˆå§‹åŒ–**ï¼Œç¡®ä¿æ¨¡å‹åœ¨å®é™…æ¨ç†æ—¶è¾¾åˆ°æœ€ä½³æ€§èƒ½ã€‚

## éæå¤§å€¼æŠ‘åˆ¶
NMS é€šè¿‡ä»¥ä¸‹æ­¥éª¤æ¥å®Œæˆè¿™ä¸ªä»»åŠ¡ï¼š
- é¦–å…ˆå¯¹æ¯ä¸ªæ¡†é€‰æ‹©æ¦‚ç‡æœ€å¤§çš„ç±»ï¼Œä¸”$conf = obj_conf * cls_conf$,`box = xywh2xyxy(x[:, :4]) `è®²åæ ‡å…·ä½“è½¬æ¢ä¸ºxyåæ ‡ç³»
- å…¶æ¬¡åˆæˆx:`[ä½ç½®ï¼Œç½®ä¿¡åº¦ï¼Œç±»åˆ«]`æ€»å…±6ä¸ªå‚æ•°ã€‚å¹¶ä¸”ç½®ä¿¡åº¦è¦å¤§äºthereshold.
- å…³é”®ç‚¹ï¼šè°ƒç”¨**Pytorch**ä¸­çš„**NMS**` i = torchvision.ops.nms(boxes, scores, iou_thres)  # NMS`ï¼Œä¿ç•™å¾—åˆ†æœ€é«˜çš„æ¡†ï¼Œä¸”åˆ é™¤ä¸å®ƒioué‡åˆåº¦é«˜äºthresholdçš„å…¶ä½™æ¡†
- è¾“å‡ºå³ä¸ºoutputï¼Œå°±æ˜¯ä¸Šä¸€æ­¥é€‰æ‹©å‡ºæ¥çš„ä¼˜é€‰æ¡†`output[xi] = x[i]`
- å¦‚æœåˆå¹¶æ¡†çš„è¯ï¼Œä¼šè®¡ç®—æ¯ä¸ªä¼˜é€‰æ¡†ä¸æ‰€æœ‰æ¡†çš„iouï¼Œå¹¶äºconfç›¸ä¹˜ï¼Œä½œä¸ºæƒé‡ã€‚
```python
def non_max_suppression(
        prediction,
        conf_thres=0.25,
        iou_thres=0.45,
        classes=None,
        agnostic=False,
        multi_label=False,
        labels=(),
        max_det=300,
        nm=0,  # number of masks
):
    """Non-Maximum Suppression (NMS) on inference results to reject overlapping detections

    Returns:
         list of detections, on (n,6) tensor per image [xyxy, conf, cls]
    """
    max_nms = 30000  # maximum number of boxes into torchvision.ops.nms() # æ¯å¼ å›¾ç‰‡anchorsçš„æœ€å¤§å€¼
    for xi, x in enumerate(prediction):  # image index, image ,å¯¹batch_sizeåšå¾ªç¯ï¼Œæ¯ä¸ªbatch_sizeéƒ½æœ‰(na*nx*ny,no)çš„è¾“å‡º
        # Compute conf
        x[:, 5:] *= x[:, 4:5]  # conf = obj_conf * cls_conf

        # Box/Mask
        box = xywh2xyxy(x[:, :4])  # center_x, center_y, width, height) to (x1, y1, x2, y2)
        mask = x[:, mi:]  # zero columns if no masks

        # Detections matrix nx6 (xyxy, conf, cls)
    else:  # best class onlyï¼Œå¯¹ç¬¬1ç»´(ç±»åˆ«ç»´åº¦)æ±‚æœ€å¤§å€¼
            conf, j = x[:, 5:mi].max(1, keepdim=True)# jä¸ºidx(å³å…·ä½“æ˜¯å“ªä¸ªç±»åˆ«)ï¼Œconfä¸ºç½®ä¿¡åº¦
            x = torch.cat((box, conf, j.float(), mask), 1)[conf.view(-1) > conf_thres] # åˆæˆ[ä½ç½®ï¼Œç½®ä¿¡åº¦ï¼Œç±»åˆ«]ä¸”åªä¿ç•™ç½®ä¿¡åº¦å¤§äºthresholdçš„æ¡†
            boxes, scores = x[:, :4] + c, x[:, 4]  # boxes (offset by class), scores
        i = torchvision.ops.nms(boxes, scores, iou_thres)  # NMS
        i = i[:max_det]  # limit detections
        if merge and (1 < n < 3E3):  # Merge NMS (boxes merged using weighted mean)
            # update boxes as boxes(i,4) = weights(i,n) * boxes(n,4)
            iou = box_iou(boxes[i], boxes) > iou_thres  # iou matrix
            weights = iou * scores[None]  # box weights
            x[i, :4] = torch.mm(weights, x[:, :4]).float() / weights.sum(1, keepdim=True)  # merged boxes
            if redundant:
                i = i[iou.sum(1) > 1]  # require redundancy

        output[xi] = x[i]
```
`x[..., 0] `è¡¨ç¤ºå–ç¬¬0åˆ—ï¼Œå½“çŸ©é˜µç»´æ•°å¾ˆé«˜(5ç»´)æ—¶æ¯”è¾ƒæ–¹ä¾¿


# valuation
valuationçš„è¾“å…¥æ˜¯modelå’Œå›¾ç‰‡ä»¥åŠå¯¹åº”çš„labelï¼Œè¾“å‡ºæ˜¯æ¨¡å‹é¢„æµ‹çš„å„ç§ç²¾åº¦ã€‚
- é¦–å…ˆéœ€è¦ä¿è¯è¾“å…¥çš„æ•°æ®ä¹Ÿè¦æŒ‰xywhï¼›å…¶æ¬¡å’Œinferenceé¡ºåºä¸€æ ·ï¼Œå…ˆè°ƒç”¨modelï¼Œè®¡ç®—å‡ºé¢„æµ‹å€¼`[tx,ty,tw,th,conf,label]`,è‹¥æ˜¯è®­ç»ƒè¿˜éœ€è¦è®¡ç®—lossã€‚æ¥ç€ä½¿ç”¨NMSï¼Œè®¡ç®—å‡ºæœ€å¤§å€¼æŠ‘åˆ¶åçš„æ¡†ã€‚
- ç°åœ¨æ˜¯valçš„å…³é”®å‡½æ•°`process_batch`,è®¡ç®—labelå’Œdetectionsï¼Œå¹¶ä¸”ä½¿labelå’Œdetectionsä¸€ä¸€å¯¹åº”ï¼›æœ€åå›ä¼ ä¸åŒçš„IOUé˜ˆå€¼ä¸‹ï¼Œæ­£ç¡®åˆ†ç±»çš„labelã€‚`return torch.tensor(correct, dtype=torch.bool, device=iouv.device)`ï¼Œ `correct[i][j]`ï¼Œè¡¨ç¤ºç¬¬iä¸ªé¢„æµ‹åœ¨Iou[j]é˜ˆå€¼ä¸‹æ˜¯å¦ä¸ºTP
- æœ€åè®¡ç®—å„ç§ç²¾åº¦çš„ç»“æœ[ç²¾åº¦è®¡ç®—](#ç²¾åº¦è®¡ç®—),å¾—åˆ°æœ€ç»ˆçš„ç»“æœ
`training = model is not None`ï¼šç‰¹æ®Šçš„ä¸éï¼Œå°±å’Œ not trueç±»ä¼¼ã€‚
```md
ğŸ” åŒ¹é…è¿‡ç¨‹æ¼”ç¤ºï¼š
å‡è®¾ï¼š

æœ‰ 2 ä¸ª GTï¼ˆlabel0 å’Œ label1ï¼‰

æ¨¡å‹é¢„æµ‹å‡ºäº† 3 ä¸ªæ¡†ï¼ˆpred0, pred1, pred2ï¼‰

æ‰€æœ‰é¢„æµ‹æ¡†ä¸æ ‡ç­¾éƒ½åŒ¹é…ç±»åˆ«ï¼ŒIoU å¦‚ä¸‹ï¼š

label0	label1
pred0	0.85	0.20
pred1	0.60	0.70
pred2	0.88	0.90

åœ¨ IoU é˜ˆå€¼ä¸º 0.5 ä¸‹ï¼Œæ»¡è¶³ IoU å’Œç±»åˆ«åŒ¹é…æ¡ä»¶çš„å€™é€‰åŒ¹é…æœ‰ï¼š

pred0 â†” label0

pred1 â†” label0

pred1 â†” label1

pred2 â†” label0

pred2 â†” label1

ğŸ§¹ ç¬¬ä¸€æ¬¡å»é‡ï¼šæ¯ä¸ª detection åªèƒ½å¯¹åº”ä¸€ä¸ª label
æŒ‰ IoU æ’åºï¼Œä¿ç•™æ¯ä¸ª detection åŒ¹é…ä¸­ IoU æœ€å¤§çš„ï¼š

pred0 â†” label0ï¼ˆ0.85ï¼‰

pred1 â†” label1ï¼ˆ0.70ï¼‰

pred2 â†” label1ï¼ˆ0.90ï¼‰

ğŸ§¹ ç¬¬äºŒæ¬¡å»é‡ï¼šæ¯ä¸ª label åªèƒ½å¯¹åº”ä¸€ä¸ª detection
label1 ç°åœ¨è¢« pred1 å’Œ pred2 åŒæ—¶â€œåŒ¹é…â€ï¼Œæˆ‘ä»¬é€‰ pred2ï¼ˆIoU é«˜ï¼‰

æœ€ç»ˆåŒ¹é…å¯¹ï¼š

pred0 â†” label0

pred2 â†” label1

ç»“æœä¸­ï¼š

pred1 æ²¡æœ‰æˆåŠŸåŒ¹é…ï¼ˆè™½ç„¶æœ‰æœºä¼šï¼‰ï¼Œè¢«è§†ä¸º False Positive

ä¸¤ä¸ª label éƒ½è¢«å‘½ä¸­


```
```python
iouv = torch.linspace(0.5, 0.95, 10, device=device)  # iou vector for mAP@0.5:0.95
 confusion_matrix = ConfusionMatrix(nc=nc)
    dt = Profile(), Profile(), Profile()  # profiling times
    with dt[0]:
    names = model.names if hasattr(model, 'names') else model.module.names  # get class names
    if isinstance(names, (list, tuple)):  # old format
        names = dict(enumerate(names))
    class_map = coco80_to_coco91_class() if is_coco else list(range(1000))
    s = ('%22s' + '%11s' * 6) % ('Class', 'Images', 'Instances', 'P', 'R', 'mAP50', 'mAP50-95')
    tp, fp, p, r, f1, mp, mr, map50, ap50, map = 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0

     if single_cls:
                pred[:, 5] = 0# å¦‚æœåªæœ‰ä¸€ä¸ªç±»åˆ«çš„è¯ï¼Œå…¨éƒ¨éƒ½ç®—ä¸€ç±»

with dt[2]:
            preds = non_max_suppression(preds,
                                        conf_thres,
                                        iou_thres,
                                        labels=lb,
                                        multi_label=True,
                                        agnostic=single_cls,
                                        max_det=max_det)# val ä¹Ÿè¦NMS


  # Metrics
        for si, pred in enumerate(preds):
            labels = targets[targets[:, 0] == si, 1:]
            nl, npr = labels.shape[0], pred.shape[0]  # number of labels, predictions(after nms)
            path, shape = Path(paths[si]), shapes[si][0]
            correct = torch.zeros(npr, niou, dtype=torch.bool, device=device)  # init
            seen += 1


  # Evaluate
            if nl:
                tbox = xywh2xyxy(labels[:, 1:5])  # target boxes
                scale_boxes(im[si].shape[1:], tbox, shape, shapes[si][1])  # native-space labels
                labelsn = torch.cat((labels[:, 0:1], tbox), 1)  # native-space labels
                correct = process_batch(predn, labelsn, iouv)
                if plots:
                    confusion_matrix.process_batch(predn, labelsn)
            stats.append((correct, pred[:, 4], pred[:, 5], labels[:, 0]))  # (correct, conf, pcls, tcls)


```

```python
def process_batch(detections, labels, iouv):
    """
    Return correct prediction matrix
    Arguments:
        detections (array[N, 6]), x1, y1, x2, y2, conf, class
        labels (array[M, 5]), class, x1, y1, x2, y2
    Returns:
        correct (array[N, 10]), for 10 IoU levels
    """
    correct = np.zeros((detections.shape[0], iouv.shape[0])).astype(bool)
    iou = box_iou(labels[:, 1:], detections[:, :4])
    correct_class = labels[:, 0:1] == detections[:, 5]
    for i in range(len(iouv)):
        x = torch.where((iou >= iouv[i]) & correct_class)  # IoU > threshold and classes match
        if x[0].shape[0]:
            matches = torch.cat((torch.stack(x, 1), iou[x[0], x[1]][:, None]), 1).cpu().numpy()  # [label, detect, iou]
            if x[0].shape[0] > 1:
                matches = matches[matches[:, 2].argsort()[::-1]]
                matches = matches[np.unique(matches[:, 1], return_index=True)[1]]
                # matches = matches[matches[:, 2].argsort()[::-1]]
                matches = matches[np.unique(matches[:, 0], return_index=True)[1]]
            correct[matches[:, 1].astype(int), i] = True
    return torch.tensor(correct, dtype=torch.bool, device=iouv.device)
```
# Results
## ConfusionMatrix
æ··æ·†çŸ©é˜µè®°å½•é¢„æµ‹ç±»åˆ«vsçœŸå®ç±»åˆ«çš„æ•°é‡ã€‚`matrix[pred_class][true_class]`
- matchsæ˜¯ä¸€ä¸ª`(k,3)`çš„æ•°ç»„ï¼Œåˆ—åˆ†åˆ«ä¸º`[ground-truth idx, decetion idx, IOU]`è¡¨ç¤ºé¢„æµ‹æ¡†idx`m1`é¢„æµ‹äº†å®æ¡†çš„idx`m0`ï¼Œå’Œå…·ä½“çš„IOUå€¼ã€‚
- ä»gronud-truthä¸­å¾ªç¯ï¼Œæ‰¾é¢„æµ‹å‡ºçš„çœŸå®æ¡†ä¸åŸå§‹çœŸå®æ¡†æ˜¯å¦æœ‰ç›¸åŒç”µï¼Œæœ‰ç›¸åŒè®¤ä¸ºè¿™æ˜¯ä¸€ä¸ªTPï¼Œå¦åˆ™æŠŠå®ƒå½“æˆèƒŒæ™¯æ¿ã€‚
```python
   m0, m1, _ = matches.transpose().astype(int)
        for i, gc in enumerate(gt_classes):
            j = m0 == i
            if n and sum(j) == 1:
                self.matrix[detection_classes[m1[j]], gc] += 1  # correct
            else:
                self.matrix[self.nc, gc] += 1  # true background
```
```python
def process_batch(self, detections, labels):
        """
        Return intersection-over-union (Jaccard index) of boxes.
        Both sets of boxes are expected to be in (x1, y1, x2, y2) format.
        Arguments:
            detections (Array[N, 6]), x1, y1, x2, y2, conf, class
            labels (Array[M, 5]), class, x1, y1, x2, y2
        Returns:
            None, updates confusion matrix accordingly
        """
        if detections is None:
            gt_classes = labels.int()
            for gc in gt_classes:
                self.matrix[self.nc, gc] += 1  # background FN
            return

        detections = detections[detections[:, 4] > self.conf]
        gt_classes = labels[:, 0].int()
        detection_classes = detections[:, 5].int()
        iou = box_iou(labels[:, 1:], detections[:, :4])

        x = torch.where(iou > self.iou_thres)
        if x[0].shape[0]:
            matches = torch.cat((torch.stack(x, 1), iou[x[0], x[1]][:, None]), 1).cpu().numpy()
            if x[0].shape[0] > 1:
                matches = matches[matches[:, 2].argsort()[::-1]]
                matches = matches[np.unique(matches[:, 1], return_index=True)[1]]
                matches = matches[matches[:, 2].argsort()[::-1]]
                matches = matches[np.unique(matches[:, 0], return_index=True)[1]]
        else:
            matches = np.zeros((0, 3))

        n = matches.shape[0] > 0
        m0, m1, _ = matches.transpose().astype(int)
        for i, gc in enumerate(gt_classes):
            j = m0 == i
            if n and sum(j) == 1:
                self.matrix[detection_classes[m1[j]], gc] += 1  # correct
            else:
                self.matrix[self.nc, gc] += 1  # true background

        if n:
            for i, dc in enumerate(detection_classes):
                if not any(m1 == i):
                    self.matrix[dc, self.nc] += 1  # predicted background
```


## ç²¾åº¦è®¡ç®—
- å¿…é¡»å¾—ä¼šå•Šï¼Œä¸ç„¶ä½ æ€ä¹ˆçŸ¥é“å“ªäº›ç²¾åº¦å…·ä½“ä»£è¡¨äº†ä»€ä¹ˆå‘¢ï¼Ÿamazingï¼Œ ç«Ÿç„¶æ˜¯è¿™ä¹ˆè®¡ç®—çš„å•Šã€‚
- `Recall=TP/nl`:æ‰€æœ‰æ­£ç¡®çš„ç±»åˆ«ä¸­é¢„æµ‹æ­£ç¡®ç±»åˆ«çš„æ¯”ä¾‹,ä¸æƒ³æ¼æ£€(å®æ»¥å‹¿ç¼º)ã€‚
- `Precision = TP/TP+NP`ï¼šæ‰€æœ‰é¢„æµ‹çš„ç±»åˆ«ä¸­é¢„æµ‹æ­£ç¡®çš„ç±»åˆ«(å¯èƒ½å°†è´Ÿæ ·æœ¬é¢„æµ‹ä¸ºæ­£æ ·æœ¬)ï¼Œä¸æƒ³é”™æŠ“(å®ç¼ºå‹¿æ»¥)ã€‚
- PRæ›²çº¿ï¼šæ¨ªåæ ‡ä¸ºRecall,çºµåæ ‡ä¸ºPrecisionï¼Œè¶Šé å·¦ä¸Šè§’è¶Šå¥½ã€‚å› ä¸ºæˆ‘ä»¬ç°åœ¨é¢„æµ‹éƒ½æ˜¯æ ¹æ®æ¦‚ç‡è¿›è¡Œï¼Œæœ€ç†æƒ³æƒ…å†µä¸º(1,1),ä½†éšç€Recallçš„å¢åŠ ï¼Œé€æ¸æŠŠæ‰€æœ‰æ­£ç¡®çš„ç±»åˆ«éƒ½é¢„æµ‹å‡ºæ¥ï¼Œæ­¤æ—¶å¿…é¡»è¦ç‰ºç‰²ä¸€äº›ç²¾åº¦ï¼ŒæŠŠä¸€äº›å¾ˆå¯èƒ½è´Ÿæ ·æœ¬é¢„æµ‹ä¸ºæ­£æ ·æœ¬(ä¾‹å¦‚åªæœ‰0.2çš„æ¦‚ç‡æ˜¯ç»¿ç¯ï¼Œæˆ‘ä»¬ä¹Ÿç®—)ï¼Œä»¥æé«˜é¢„æµ‹å‡ºçš„æ­£ç¡®ç±»åˆ«çš„æ€»é‡ã€‚
    - è‹¥éœ€è¦æé«˜ç²¾åº¦ï¼Œæˆ‘ä»¬ä¹Ÿå¿…é¡»ç‰ºç‰²Recall,åªè¦æœ‰ä¸€ç‚¹å¯èƒ½è¢«é¢„æµ‹ä¸ºè´Ÿæ ·æœ¬çš„æ­£æ ·æœ¬æˆ‘ä»¬éƒ½ä¸è¦(å°±ç®—æœ‰0.8æ¦‚ç‡æ˜¯ç»¿ç¯æˆ‘ä»¬ä¹Ÿä¸è¦)ã€‚
```md
ä¸¾ä¸ªä¾‹å­ï¼š
ä½ åœ¨æ£€æµ‹â€œçŒ«â€ï¼Œæ¨¡å‹è¾“å‡ºå¾ˆå¤šå€™é€‰æ¡†ï¼Œæ¯ä¸ªæ¡†æœ‰ä¸ªç½®ä¿¡åº¦ï¼ˆconfidenceï¼‰ï¼š

å¦‚æœä½  æé«˜ç½®ä¿¡åº¦é˜ˆå€¼ï¼ˆæ¯”å¦‚åªä¿ç•™ >0.9 çš„æ¡†ï¼‰ï¼š

âœ”ï¸ ä½ ä¿ç•™çš„é¢„æµ‹å¤§å¤šæ•°éƒ½æ˜¯çœŸçŒ«ï¼ˆPrecision é«˜äº†ï¼‰

âŒ ä½†å¾ˆå¤šçœŸæ­£çš„çŒ«è¢«ä½ è¿‡æ»¤æ‰äº†ï¼ˆRecall ä½äº†ï¼‰

å¦‚æœä½  é™ä½ç½®ä¿¡åº¦é˜ˆå€¼ï¼ˆæ¯”å¦‚åªè¦ >0.2 å°±ç®—çŒ«ï¼‰ï¼š

âœ”ï¸ ä½ å‡ ä¹ä¸ä¼šæ¼çŒ«äº†ï¼ˆRecall é«˜äº†ï¼‰

âŒ ä½†ä½ é¢„æµ‹çš„ä¸€å †â€œçŒ«â€ä¸­æœ‰å¾ˆå¤šæ˜¯å‡çŒ«ï¼ˆPrecision é™ä½ï¼‰
```
- `AP(Average Precision)`:PRæ›²çº¿ä¸‹çš„é¢ç§¯ï¼Œè¡¨ç¤ºå¹³å‡ç²¾åº¦ã€‚(YOLOæ£€æµ‹æ—¶ä¼šæœ‰ä¸åŒIOUé˜ˆå€¼å¯¹åº”çš„ç²¾åº¦)
- `MAP(mean Average Precision)`:æ‰€æœ‰ç±»åˆ«çš„å¹³å‡ç²¾åº¦(MAP@0.5)è¡¨ç¤ºIOUé˜ˆå€¼ä¸º0.5æ—¶çš„MPAï¼Œ`MAP@[.5:.95]`è¡¨ç¤ºé˜ˆå€¼from 0.5 to 0.95çš„MAPçš„å¹³å‡å€¼ã€‚
| ç±»åˆ«  | AP@0.5 | AP@0.55 | ... | AP@0.95 |
| --- | ------ | ------- | --- | ------- |
| cat | 0.80   | 0.75    | ... | 0.40    |
| dog | 0.78   | 0.72    | ... | 0.35    |
| car | 0.70   | 0.68    | ... | 0.30    |
MAP@0.5= (0.80+0.78+0.70)/3 = 0.76
- `F1 = (2*P*R)/(P+R+eps)`ï¼šPrecision å’Œ Recallçš„è°ƒå’Œå¹³å‡ï¼Œä¸ºäº†å¹³è¡¡Precisionå’ŒRecallï¼Œè°ƒå’Œå¹³å‡æ˜¯å› ä¸ºå®ƒå¯ä»¥æƒ©ç½šä¸¤è€…ä¸å¹³è¡¡çš„æƒ…å†µï¼Œè‹¥ä¸€æ–¹è¾ƒä½ï¼Œåˆ™F1è¾ƒä½ï¼Œåªæœ‰åœ¨ä¸¤è€…éƒ½é«˜åˆ†æ—¶ï¼ŒF1æ‰é«˜ã€‚
| Precision | Recall | ç®—æœ¯å¹³å‡ | è°ƒå’Œå¹³å‡ï¼ˆF1ï¼‰ |
| --------- | ------ | ---- | -------- |
| 1.0       | 0.0    | 0.5  | 0.0 âŒ    |
| 0.9       | 0.9    | 0.9  | 0.9 âœ…    |
| 0.6       | 0.3    | 0.45 | 0.4      |
| 0.9       | 0.1    | 0.5  | 0.18 âŒ   |

```python
def ap_per_class(tp, conf, pred_cls, target_cls, plot=False, save_dir='.', names=(), eps=1e-16, prefix=""):
    """ Compute the average precision, given the recall and precision curves.
    Source: https://github.com/rafaelpadilla/Object-Detection-Metrics.
    # Arguments
        tp:  True positives (nparray, nx1 or nx10).
        conf:  Objectness value from 0-1 (nparray).
        pred_cls:  Predicted object classes (nparray).
        target_cls:  True object classes (nparray).
        plot:  Plot precision-recall curve at mAP@0.5
        save_dir:  Plot save directory
    # Returns
        The average precision as computed in py-faster-rcnn.
    """

    # Sort by objectness
    i = np.argsort(-conf)
    tp, conf, pred_cls = tp[i], conf[i], pred_cls[i] # æŒ‰ç´¢å¼•é‡æ–°æ’åº

    # Find unique classes
    unique_classes, nt = np.unique(target_cls, return_counts=True) # ntä¸ºæ¯ä¸ªç±»åˆ«çœŸå®ç›®æ ‡çš„æ•°é‡
    nc = unique_classes.shape[0]  # number of classes, number of detections

    # Create Precision-Recall curve and compute AP for each class
    px, py = np.linspace(0, 1, 1000), []  # for plotting
    ap, p, r = np.zeros((nc, tp.shape[1])), np.zeros((nc, 1000)), np.zeros((nc, 1000))
    for ci, c in enumerate(unique_classes):
        i = pred_cls == c
        n_l = nt[ci]  # number of labels
        n_p = i.sum()  # number of predictions
        if n_p == 0 or n_l == 0:
            continue

        # Accumulate FPs and TPs
        fpc = (1 - tp[i]).cumsum(0)
        tpc = tp[i].cumsum(0)

        # Recall
        recall = tpc / (n_l + eps)  # recall curve
        r[ci] = np.interp(-px, -conf[i], recall[:, 0], left=0)  # negative x, xp because xp decreases

        # Precision
        precision = tpc / (tpc + fpc)  # precision curve
        p[ci] = np.interp(-px, -conf[i], precision[:, 0], left=1)  # p at pr_score

        # AP from recall-precision curve
        for j in range(tp.shape[1]):
            ap[ci, j], mpre, mrec = compute_ap(recall[:, j], precision[:, j])
            if plot and j == 0:
                py.append(np.interp(px, mrec, mpre))  # precision at mAP@0.5

    # Compute F1 (harmonic mean of precision and recall)
    f1 = 2 * p * r / (p + r + eps)
    names = [v for k, v in names.items() if k in unique_classes]  # list: only classes that have data
    names = dict(enumerate(names))  # to dict
    if plot:
        plot_pr_curve(px, py, ap, Path(save_dir) / f'{prefix}PR_curve.png', names)
        plot_mc_curve(px, f1, Path(save_dir) / f'{prefix}F1_curve.png', names, ylabel='F1')
        plot_mc_curve(px, p, Path(save_dir) / f'{prefix}P_curve.png', names, ylabel='Precision')
        plot_mc_curve(px, r, Path(save_dir) / f'{prefix}R_curve.png', names, ylabel='Recall')

    i = smooth(f1.mean(0), 0.1).argmax()  # max F1 index
    p, r, f1 = p[:, i], r[:, i], f1[:, i]
    tp = (r * nt).round()  # true positives
    fp = (tp / (p + eps) - tp).round()  # false positives
    return tp, fp, p, r, f1, ap, unique_classes.astype(int)
```

## scale_boxes
YOLOä¸€èˆ¬ä¼šå¯¹å›¾åƒè¿›è¡Œresizeï¼Œç»Ÿä¸€åˆ°`640*640`
```python
def scale_boxes(img1_shape, boxes, img0_shape, ratio_pad=None)
# Rescale boxes (xyxy) from img1_shape to img0_shape
```

## box_iou
```python
def box_iou(box1, box2, eps=1e-7):
    # https://github.com/pytorch/vision/blob/master/torchvision/ops/boxes.py
    """
    Return intersection-over-union (Jaccard index) of boxes.
    Both sets of boxes are expected to be in (x1, y1, x2, y2) format.
    Arguments:
        box1 (Tensor[N, 4])
        box2 (Tensor[M, 4])
    Returns:
        iou (Tensor[N, M]): the NxM matrix containing the pairwise
            IoU values for every element in boxes1 and boxes2
    """

    # inter(N,M) = (rb(N,M,2) - lt(N,M,2)).clamp(0).prod(2)
    (a1, a2), (b1, b2) = box1.unsqueeze(1).chunk(2, 2), box2.unsqueeze(0).chunk(2, 2)
    inter = (torch.min(a2, b2) - torch.max(a1, b1)).clamp(0).prod(2)

    # IoU = inter / (area1 + area2 - inter)
    return inter / ((a2 - a1).prod(2) + (b2 - b1).prod(2) - inter + eps)
```
